{"file_contents":{"modules/text_analytics.py":{"content":"import pandas as pd\nimport numpy as np\nimport streamlit as st\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom typing import Dict, List, Tuple, Optional\nimport sys\nsys.path.append('..')\nfrom utils.error_handler import safe_execute, validate_dataframe\n\ndef analyze_sentiment(text_series: pd.Series) -> pd.DataFrame:\n    try:\n        sentiments = []\n        for text in text_series:\n            if pd.isna(text) or not isinstance(text, str):\n                sentiments.append({'polarity': 0, 'subjectivity': 0, 'label': 'Neutral'})\n                continue\n            \n            blob = TextBlob(str(text))\n            polarity = blob.sentiment.polarity\n            \n            if polarity > 0.1:\n                label = 'Positive'\n            elif polarity < -0.1:\n                label = 'Negative'\n            else:\n                label = 'Neutral'\n            \n            sentiments.append({\n                'polarity': polarity,\n                'subjectivity': blob.sentiment.subjectivity,\n                'label': label\n            })\n        \n        return pd.DataFrame(sentiments)\n        \n    except Exception as e:\n        st.error(f\"‚ùå Sentiment analysis failed: {str(e)}\")\n        return pd.DataFrame()\n\ndef generate_wordcloud(text_series: pd.Series, max_words: int = 100) -> Optional[WordCloud]:\n    try:\n        text = ' '.join([str(t) for t in text_series.dropna() if isinstance(t, str)])\n        \n        if not text.strip():\n            st.warning(\"‚ö†Ô∏è No text data available for word cloud\")\n            return None\n        \n        wordcloud = WordCloud(\n            width=800,\n            height=400,\n            background_color='white',\n            max_words=max_words,\n            colormap='viridis'\n        ).generate(text)\n        \n        return wordcloud\n        \n    except Exception as e:\n        st.error(f\"‚ùå Word cloud generation failed: {str(e)}\")\n        return None\n\ndef extract_ngrams(text_series: pd.Series, n: int = 2, top_k: int = 10) -> List[Tuple[str, int]]:\n    try:\n        from nltk import ngrams\n        from nltk.tokenize import word_tokenize\n        import nltk\n        \n        try:\n            nltk.data.find('tokenizers/punkt')\n        except LookupError:\n            nltk.download('punkt', quiet=True)\n            nltk.download('punkt_tab', quiet=True)\n        \n        all_ngrams = []\n        for text in text_series.dropna():\n            if not isinstance(text, str):\n                continue\n            \n            tokens = word_tokenize(str(text).lower())\n            tokens = [t for t in tokens if t.isalnum()]\n            \n            text_ngrams = list(ngrams(tokens, n))\n            all_ngrams.extend([' '.join(ng) for ng in text_ngrams])\n        \n        if not all_ngrams:\n            return []\n        \n        counter = Counter(all_ngrams)\n        return counter.most_common(top_k)\n        \n    except Exception as e:\n        st.warning(f\"‚ö†Ô∏è N-gram extraction failed: {str(e)}\")\n        return []\n\ndef get_text_statistics(text_series: pd.Series) -> Dict:\n    try:\n        stats = {\n            'total_texts': len(text_series),\n            'non_empty': text_series.notna().sum(),\n            'avg_length': 0,\n            'max_length': 0,\n            'min_length': 0,\n            'total_words': 0,\n            'avg_words': 0\n        }\n        \n        valid_texts = [str(t) for t in text_series.dropna() if isinstance(t, str)]\n        \n        if valid_texts:\n            lengths = [len(t) for t in valid_texts]\n            stats['avg_length'] = np.mean(lengths)\n            stats['max_length'] = max(lengths)\n            stats['min_length'] = min(lengths)\n            \n            word_counts = [len(t.split()) for t in valid_texts]\n            stats['total_words'] = sum(word_counts)\n            stats['avg_words'] = np.mean(word_counts)\n        \n        return stats\n        \n    except Exception as e:\n        st.warning(f\"‚ö†Ô∏è Text statistics failed: {str(e)}\")\n        return {}\n\ndef analyze_text_column(df: pd.DataFrame, column: str) -> Dict:\n    if column not in df.columns:\n        st.error(f\"‚ùå Column '{column}' not found\")\n        return {}\n    \n    try:\n        text_col = df[column]\n        \n        results = {\n            'statistics': get_text_statistics(text_col),\n            'sentiment': analyze_sentiment(text_col),\n            'wordcloud': generate_wordcloud(text_col),\n            'bigrams': extract_ngrams(text_col, n=2, top_k=10),\n            'trigrams': extract_ngrams(text_col, n=3, top_k=10)\n        }\n        \n        return results\n        \n    except Exception as e:\n        st.error(f\"‚ùå Text analysis failed: {str(e)}\")\n        return {}\n","size_bytes":4733},"modules/visualizations.py":{"content":"import plotly.express as px\nimport plotly.graph_objects as go\nimport pandas as pd\nimport numpy as np\nimport streamlit as st\nfrom typing import Optional, List\nimport sys\nsys.path.append('..')\nfrom utils.helpers import get_numeric_columns, get_categorical_columns\n\ndef create_scatter_plot(df: pd.DataFrame, x_col: str, y_col: str, color_by: Optional[str] = None):\n    try:\n        fig = px.scatter(\n            df,\n            x=x_col,\n            y=y_col,\n            color=color_by if color_by else None,\n            title=f\"{y_col} vs {x_col}\",\n            template=\"plotly_white\",\n            height=500\n        )\n        \n        fig.update_layout(\n            hovermode='closest',\n            showlegend=True if color_by else False\n        )\n        \n        return fig\n    except Exception as e:\n        st.error(f\"‚ùå Scatter plot failed: {str(e)}\")\n        return None\n\ndef create_bar_chart(df: pd.DataFrame, x_col: str, y_col: Optional[str] = None):\n    try:\n        if y_col:\n            fig = px.bar(\n                df,\n                x=x_col,\n                y=y_col,\n                title=f\"{y_col} by {x_col}\",\n                template=\"plotly_white\",\n                height=500\n            )\n        else:\n            value_counts = df[x_col].value_counts()\n            fig = px.bar(\n                x=value_counts.index,\n                y=value_counts.values,\n                title=f\"Distribution of {x_col}\",\n                template=\"plotly_white\",\n                height=500,\n                labels={'x': x_col, 'y': 'Count'}\n            )\n        \n        return fig\n    except Exception as e:\n        st.error(f\"‚ùå Bar chart failed: {str(e)}\")\n        return None\n\ndef create_histogram(df: pd.DataFrame, column: str, bins: int = 30):\n    try:\n        fig = px.histogram(\n            df,\n            x=column,\n            nbins=bins,\n            title=f\"Distribution of {column}\",\n            template=\"plotly_white\",\n            height=500\n        )\n        \n        fig.update_layout(showlegend=False)\n        \n        return fig\n    except Exception as e:\n        st.error(f\"‚ùå Histogram failed: {str(e)}\")\n        return None\n\ndef create_box_plot(df: pd.DataFrame, y_col: str, x_col: Optional[str] = None):\n    try:\n        fig = px.box(\n            df,\n            y=y_col,\n            x=x_col if x_col else None,\n            title=f\"Box Plot of {y_col}\",\n            template=\"plotly_white\",\n            height=500\n        )\n        \n        return fig\n    except Exception as e:\n        st.error(f\"‚ùå Box plot failed: {str(e)}\")\n        return None\n\ndef create_correlation_heatmap(df: pd.DataFrame):\n    try:\n        numeric_cols = get_numeric_columns(df)\n        \n        if len(numeric_cols) < 2:\n            st.warning(\"‚ö†Ô∏è Need at least 2 numeric columns for correlation\")\n            return None\n        \n        corr_matrix = df[numeric_cols].corr()\n        \n        fig = go.Figure(data=go.Heatmap(\n            z=corr_matrix.values,\n            x=corr_matrix.columns,\n            y=corr_matrix.columns,\n            colorscale='RdBu',\n            zmid=0,\n            text=np.round(corr_matrix.values, 2),\n            texttemplate='%{text}',\n            textfont={\"size\": 10},\n            colorbar=dict(title=\"Correlation\")\n        ))\n        \n        fig.update_layout(\n            title=\"Correlation Heatmap\",\n            template=\"plotly_white\",\n            height=600,\n            xaxis_showgrid=False,\n            yaxis_showgrid=False\n        )\n        \n        return fig\n    except Exception as e:\n        st.error(f\"‚ùå Correlation heatmap failed: {str(e)}\")\n        return None\n\ndef create_line_chart(df: pd.DataFrame, x_col: str, y_col: str, color_by: Optional[str] = None):\n    try:\n        fig = px.line(\n            df,\n            x=x_col,\n            y=y_col,\n            color=color_by if color_by else None,\n            title=f\"{y_col} over {x_col}\",\n            template=\"plotly_white\",\n            height=500\n        )\n        \n        return fig\n    except Exception as e:\n        st.error(f\"‚ùå Line chart failed: {str(e)}\")\n        return None\n\ndef create_violin_plot(df: pd.DataFrame, y_col: str, x_col: Optional[str] = None):\n    try:\n        fig = px.violin(\n            df,\n            y=y_col,\n            x=x_col if x_col else None,\n            title=f\"Violin Plot of {y_col}\",\n            template=\"plotly_white\",\n            height=500,\n            box=True\n        )\n        \n        return fig\n    except Exception as e:\n        st.error(f\"‚ùå Violin plot failed: {str(e)}\")\n        return None\n\ndef create_confusion_matrix_plot(cm: np.ndarray, labels: Optional[List] = None):\n    try:\n        if labels is None:\n            labels = [f\"Class {i}\" for i in range(len(cm))]\n        \n        fig = go.Figure(data=go.Heatmap(\n            z=cm,\n            x=labels,\n            y=labels,\n            colorscale='Blues',\n            text=cm,\n            texttemplate='%{text}',\n            textfont={\"size\": 12},\n            colorbar=dict(title=\"Count\")\n        ))\n        \n        fig.update_layout(\n            title=\"Confusion Matrix\",\n            xaxis_title=\"Predicted\",\n            yaxis_title=\"Actual\",\n            template=\"plotly_white\",\n            height=500\n        )\n        \n        return fig\n    except Exception as e:\n        st.error(f\"‚ùå Confusion matrix plot failed: {str(e)}\")\n        return None\n\ndef create_feature_importance_plot(importance_dict: dict, top_n: int = 10):\n    try:\n        sorted_features = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)[:top_n]\n        \n        features, importances = zip(*sorted_features)\n        \n        fig = go.Figure(data=[\n            go.Bar(\n                x=list(importances),\n                y=list(features),\n                orientation='h',\n                marker_color='indianred'\n            )\n        ])\n        \n        fig.update_layout(\n            title=f\"Top {top_n} Feature Importances\",\n            xaxis_title=\"Importance\",\n            yaxis_title=\"Features\",\n            template=\"plotly_white\",\n            height=500,\n            yaxis={'categoryorder': 'total ascending'}\n        )\n        \n        return fig\n    except Exception as e:\n        st.error(f\"‚ùå Feature importance plot failed: {str(e)}\")\n        return None\n\ndef download_plotly_chart(fig, filename: str, format: str = \"png\"):\n    try:\n        if format == \"png\":\n            img_bytes = fig.to_image(format=\"png\", width=1200, height=800)\n            st.download_button(\n                label=\"üì• Download PNG\",\n                data=img_bytes,\n                file_name=filename,\n                mime=\"image/png\"\n            )\n        elif format == \"html\":\n            html_bytes = fig.to_html().encode()\n            st.download_button(\n                label=\"üì• Download HTML\",\n                data=html_bytes,\n                file_name=filename.replace('.png', '.html'),\n                mime=\"text/html\"\n            )\n    except Exception as e:\n        st.warning(f\"‚ö†Ô∏è Download failed: {str(e)}\")\n","size_bytes":7046},"modules/time_series.py":{"content":"import pandas as pd\nimport numpy as np\nimport streamlit as st\nfrom typing import Dict, Tuple, Optional\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.stattools import adfuller, acf, pacf\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nimport matplotlib.pyplot as plt\nfrom utils.error_handler import safe_execute, log_error\n\ndef check_stationarity(series: pd.Series) -> Dict:\n    try:\n        result = adfuller(series.dropna())\n        \n        return {\n            'test_statistic': result[0],\n            'p_value': result[1],\n            'critical_values': result[4],\n            'is_stationary': result[1] < 0.05\n        }\n    except Exception as e:\n        log_error(\"Stationarity Test\", e)\n        return None\n\ndef fit_arima_model(\n    series: pd.Series,\n    order: Tuple[int, int, int] = (1, 1, 1),\n    forecast_steps: int = 10\n) -> Dict:\n    try:\n        series_clean = series.dropna()\n        \n        model = ARIMA(series_clean, order=order)\n        fitted_model = model.fit()\n        \n        forecast = fitted_model.forecast(steps=forecast_steps)\n        \n        return {\n            'model': fitted_model,\n            'forecast': forecast,\n            'aic': fitted_model.aic,\n            'bic': fitted_model.bic,\n            'summary': fitted_model.summary(),\n            'residuals': fitted_model.resid\n        }\n    except Exception as e:\n        log_error(\"ARIMA Model\", e)\n        return None\n\ndef fit_sarima_model(\n    series: pd.Series,\n    order: Tuple[int, int, int] = (1, 1, 1),\n    seasonal_order: Tuple[int, int, int, int] = (1, 1, 1, 12),\n    forecast_steps: int = 10\n) -> Dict:\n    try:\n        series_clean = series.dropna()\n        \n        model = SARIMAX(series_clean, order=order, seasonal_order=seasonal_order)\n        fitted_model = model.fit(disp=False)\n        \n        forecast = fitted_model.forecast(steps=forecast_steps)\n        \n        return {\n            'model': fitted_model,\n            'forecast': forecast,\n            'aic': fitted_model.aic,\n            'bic': fitted_model.bic,\n            'summary': fitted_model.summary(),\n            'residuals': fitted_model.resid\n        }\n    except Exception as e:\n        log_error(\"SARIMA Model\", e)\n        return None\n\ndef decompose_time_series(\n    series: pd.Series,\n    period: int = 12,\n    model: str = 'additive'\n) -> Dict:\n    try:\n        series_clean = series.dropna()\n        \n        if len(series_clean) < 2 * period:\n            return {\n                'error': f'Time series too short for period {period}. Need at least {2*period} observations.'\n            }\n        \n        decomposition = seasonal_decompose(series_clean, model=model, period=period)\n        \n        return {\n            'trend': decomposition.trend,\n            'seasonal': decomposition.seasonal,\n            'residual': decomposition.resid,\n            'observed': decomposition.observed\n        }\n    except Exception as e:\n        log_error(\"Time Series Decomposition\", e)\n        return None\n\ndef auto_arima(series: pd.Series, max_p: int = 3, max_d: int = 2, max_q: int = 3) -> Dict:\n    try:\n        best_aic = np.inf\n        best_order = None\n        best_model = None\n        \n        for p in range(max_p + 1):\n            for d in range(max_d + 1):\n                for q in range(max_q + 1):\n                    try:\n                        model = ARIMA(series.dropna(), order=(p, d, q))\n                        fitted = model.fit()\n                        \n                        if fitted.aic < best_aic:\n                            best_aic = fitted.aic\n                            best_order = (p, d, q)\n                            best_model = fitted\n                    except:\n                        continue\n        \n        if best_model is None:\n            return None\n        \n        forecast = best_model.forecast(steps=10)\n        \n        return {\n            'model': best_model,\n            'best_order': best_order,\n            'aic': best_aic,\n            'bic': best_model.bic,\n            'forecast': forecast,\n            'summary': best_model.summary()\n        }\n    except Exception as e:\n        log_error(\"Auto ARIMA\", e)\n        return None\n\ndef plot_acf_pacf(series: pd.Series, lags: int = 40):\n    try:\n        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n        \n        plot_acf(series.dropna(), lags=lags, ax=ax1)\n        ax1.set_title('Autocorrelation Function (ACF)')\n        \n        plot_pacf(series.dropna(), lags=lags, ax=ax2)\n        ax2.set_title('Partial Autocorrelation Function (PACF)')\n        \n        plt.tight_layout()\n        return fig\n    except Exception as e:\n        log_error(\"ACF/PACF Plot\", e)\n        return None\n\ndef calculate_forecast_metrics(actual: pd.Series, predicted: pd.Series) -> Dict:\n    try:\n        mae = np.mean(np.abs(actual - predicted))\n        mse = np.mean((actual - predicted) ** 2)\n        rmse = np.sqrt(mse)\n        mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n        \n        return {\n            'MAE': mae,\n            'MSE': mse,\n            'RMSE': rmse,\n            'MAPE': mape\n        }\n    except Exception as e:\n        log_error(\"Forecast Metrics\", e)\n        return None\n","size_bytes":5332},"attached_assets/replit_1763157388116.md":{"content":"# AI Data Analysis Platform\n\n## Overview\n\nAn AI-powered data analysis platform built with Streamlit that provides comprehensive analytics capabilities through Google's Gemini 2.5 Flash AI. The platform offers automated machine learning, interactive visualizations, text analytics, and intelligent data processing with a conversational AI interface. Users can upload datasets in multiple formats, perform automated ML model training and comparison, generate interactive dashboards, and export results in various formats including PDF reports, Excel files, and Jupyter notebooks.\n\n## User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n## System Architecture\n\n### Frontend Architecture\n\n**Framework**: Streamlit-based single-page application with responsive design\n- **Rationale**: Streamlit provides rapid development for data science applications with built-in state management and reactive UI components\n- **Layout**: Wide layout with expandable sidebar, responsive CSS for mobile/tablet/desktop breakpoints\n- **State Management**: Session-based state management through Streamlit's `session_state` for maintaining user data, model results, and conversation history across interactions\n- **UI Components**: Multi-column layouts, tabs for different analysis sections, and collapsible sections for clean information hierarchy\n\n### Backend Architecture\n\n**Core Processing Modules**:\n\n1. **Data Processing Layer** (`modules/data_processing.py`)\n   - Multi-format file parsing (CSV, Excel, JSON, Parquet, TSV)\n   - Automated data profiling and quality assessment\n   - Data cleaning with multiple strategies (imputation, outlier detection, deduplication)\n   - Uses scikit-learn for preprocessing (StandardScaler, MinMaxScaler, LabelEncoder)\n\n2. **Machine Learning Engine** (`modules/ml_models.py`)\n   - Automated model training and comparison for classification and regression tasks\n   - Supports 10+ algorithms: Random Forest, Logistic Regression, SVM, Ridge, Lasso, XGBoost, LightGBM\n   - Optional hyperparameter tuning via GridSearchCV\n   - Clustering (KMeans, DBSCAN) and dimensionality reduction (PCA)\n   - Feature importance calculation and SHAP value integration\n   - **Design Decision**: Uses ensemble of algorithms to provide users with best model recommendations rather than requiring manual selection\n\n3. **Text Analytics Module** (`modules/text_analytics.py`)\n   - Sentiment analysis using TextBlob for polarity and subjectivity scoring\n   - Word cloud generation with customizable parameters\n   - Topic extraction and text statistics\n   - Categorical sentiment labeling (Positive/Negative/Neutral)\n\n4. **Visualization Engine** (`modules/visualizations.py`)\n   - Interactive plots using Plotly (scatter, bar, histogram, box, violin, heatmaps, line charts)\n   - Specialized ML visualizations (confusion matrices, feature importance plots)\n   - Responsive design with consistent theming\n   - **Chosen over Matplotlib**: Plotly provides interactivity and better mobile responsiveness\n\n5. **AI Chat Integration** (`modules/gemini_integration.py`)\n   - Google Gemini 2.5 Flash integration with function calling capabilities\n   - Conversational interface for data analysis queries\n   - Context-aware responses using dataset metadata\n   - Function calling for automated actions (profiling, cleaning, visualization requests)\n   - **Design Pattern**: Tool-augmented generation where AI can trigger specific analysis functions\n\n6. **Export Handler** (`modules/export_handler.py`)\n   - Multi-format export: CSV, Excel, JSON, PDF reports\n   - Model serialization using joblib\n   - Jupyter notebook generation for reproducible analysis\n   - FPDF-based PDF report generation\n\n### Utility Layer\n\n**Error Handling** (`utils/error_handler.py`):\n- Centralized error logging to file system\n- User-friendly error messages with actionable solutions\n- Safe execution wrapper for all critical operations\n- Data validation at entry points\n\n**Rate Limiting** (`utils/rate_limiter.py`):\n- Protects against Gemini API free tier limits (15 requests/minute, 1500/day)\n- Session-based rate tracking using timestamps\n- Queue system for managing pending requests\n- Real-time feedback on remaining quota\n\n**Helper Functions** (`utils/helpers.py`):\n- Data type detection and column classification\n- Quality score calculation algorithm\n- Number formatting utilities\n- Session state initialization\n\n### Data Flow Architecture\n\n1. **Upload**: User uploads file ‚Üí Format detection ‚Üí Pandas DataFrame creation\n2. **Profile**: Automatic profiling triggers ‚Üí Statistical analysis ‚Üí Quality assessment\n3. **Clean**: User selects cleaning strategies ‚Üí Applied transformations ‚Üí Updated dataset\n4. **Analyze**: User requests analysis ‚Üí ML models train OR visualizations generate OR AI chat processes query\n5. **Export**: Results compilation ‚Üí Format conversion ‚Üí Download delivery\n\n### Design Patterns\n\n**Separation of Concerns**: Each module has single responsibility (data processing, ML, visualization, export)\n\n**Defensive Programming**: Extensive validation at module boundaries with graceful degradation\n\n**Progressive Enhancement**: Core functionality works without advanced features (XGBoost/LightGBM optional)\n\n**Mobile-First Responsive Design**: CSS media queries adapt layout for different screen sizes\n\n## External Dependencies\n\n### AI & Machine Learning Services\n\n**Google Gemini 2.5 Flash API**:\n- Purpose: Conversational AI assistant with function calling\n- Integration: `google-generativeai` Python client\n- Authentication: API key via environment variable `GEMINI_API_KEY`\n- Rate Limits: 15 requests/minute, 1500 requests/day (free tier)\n- Use Case: Natural language queries about data, automated analysis suggestions\n\n### Python Libraries\n\n**Core Framework**:\n- `streamlit`: Web application framework for the entire UI\n- `pandas`: Primary data manipulation and analysis\n- `numpy`: Numerical computations\n\n**Machine Learning**:\n- `scikit-learn`: ML algorithms, preprocessing, model evaluation\n- `xgboost`: Gradient boosting (optional, graceful fallback)\n- `lightgbm`: Fast gradient boosting (optional, graceful fallback)\n- `joblib`: Model serialization\n\n**Visualization**:\n- `plotly`: Interactive plotting library\n- `matplotlib`: Backend for some visualizations\n- `wordcloud`: Text visualization\n\n**Text Processing**:\n- `textblob`: Sentiment analysis and NLP\n\n**Export**:\n- `fpdf`: PDF report generation\n- `openpyxl`: Excel file operations\n\n**Utilities**:\n- Standard library modules: `os`, `json`, `datetime`, `logging`, `io`\n\n### Deployment Configuration\n\n**Railway Platform**:\n- Build system: Nixpacks (configured via `railway.json`)\n- Start command: `streamlit run app.py --server.port=$PORT --server.address=0.0.0.0 --server.headless=true`\n- Restart policy: On failure with max 10 retries\n- Environment variables required: `GEMINI_API_KEY`\n\n### File System Dependencies\n\n**Local Storage**:\n- `app_errors.log`: Error logging file\n- Temporary model files for serialization\n- Session-based uploaded files (handled by Streamlit)\n\n**Note**: No persistent database is used; all data processing is in-memory during session lifecycle.","size_bytes":7153},"modules/ml_models.py":{"content":"import pandas as pd\nimport numpy as np\nimport streamlit as st\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.linear_model import LogisticRegression, Ridge, Lasso\nfrom sklearn.svm import SVC, SVR\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, confusion_matrix\nfrom sklearn.cluster import KMeans, DBSCAN\nfrom sklearn.decomposition import PCA\nfrom typing import Dict, List, Tuple, Optional\nimport joblib\ntry:\n    import xgboost as xgb\n    import lightgbm as lgb\n    XGBOOST_AVAILABLE = True\nexcept:\n    XGBOOST_AVAILABLE = False\n\nimport sys\nsys.path.append('..')\nfrom utils.error_handler import safe_execute, validate_dataframe\nfrom utils.helpers import get_numeric_columns\n\ndef train_classification_models(\n    df: pd.DataFrame,\n    target_column: str,\n    models: List[str] = None,\n    test_size: float = 0.2,\n    tune_hyperparameters: bool = False\n) -> Dict:\n    \n    if not validate_dataframe(df, min_rows=50, operation=\"classification\"):\n        return {}\n    \n    if target_column not in df.columns:\n        st.error(f\"‚ùå Target column '{target_column}' not found\")\n        return {}\n    \n    try:\n        X = df.drop(columns=[target_column])\n        y = df[target_column]\n        \n        numeric_cols = get_numeric_columns(X)\n        if not numeric_cols:\n            st.error(\"‚ùå No numeric columns for features\")\n            return {}\n        \n        X = X[numeric_cols]\n        X = X.fillna(X.mean())\n        \n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n        \n        if models is None:\n            models = ['random_forest', 'logistic']\n            if XGBOOST_AVAILABLE:\n                models.append('xgboost')\n        \n        results = {}\n        \n        for model_name in models:\n            try:\n                if model_name == 'random_forest':\n                    model = RandomForestClassifier(n_estimators=100, random_state=42)\n                elif model_name == 'xgboost' and XGBOOST_AVAILABLE:\n                    model = xgb.XGBClassifier(n_estimators=100, random_state=42)\n                elif model_name == 'logistic':\n                    model = LogisticRegression(max_iter=1000, random_state=42)\n                elif model_name == 'svm':\n                    model = SVC(probability=True, random_state=42)\n                elif model_name == 'lightgbm' and XGBOOST_AVAILABLE:\n                    model = lgb.LGBMClassifier(n_estimators=100, random_state=42, verbose=-1)\n                else:\n                    continue\n                \n                model.fit(X_train, y_train)\n                y_pred = model.predict(X_test)\n                \n                metrics = {\n                    'accuracy': accuracy_score(y_test, y_pred),\n                    'precision': precision_score(y_test, y_pred, average='weighted', zero_division=0),\n                    'recall': recall_score(y_test, y_pred, average='weighted', zero_division=0),\n                    'f1': f1_score(y_test, y_pred, average='weighted', zero_division=0)\n                }\n                \n                try:\n                    y_pred_proba = model.predict_proba(X_test)\n                    if len(np.unique(y_test)) == 2:\n                        metrics['roc_auc'] = roc_auc_score(y_test, y_pred_proba[:, 1])\n                except:\n                    pass\n                \n                results[model_name] = {\n                    'model': model,\n                    'metrics': metrics,\n                    'predictions': y_pred,\n                    'confusion_matrix': confusion_matrix(y_test, y_pred).tolist()\n                }\n                \n            except Exception as e:\n                st.warning(f\"‚ö†Ô∏è {model_name} training failed: {str(e)[:50]}\")\n                continue\n        \n        return results\n        \n    except Exception as e:\n        st.error(f\"‚ùå Classification failed: {str(e)}\")\n        return {}\n\ndef train_regression_models(\n    df: pd.DataFrame,\n    target_column: str,\n    models: List[str] = None,\n    test_size: float = 0.2\n) -> Dict:\n    \n    if not validate_dataframe(df, min_rows=50, operation=\"regression\"):\n        return {}\n    \n    if target_column not in df.columns:\n        st.error(f\"‚ùå Target column '{target_column}' not found\")\n        return {}\n    \n    try:\n        X = df.drop(columns=[target_column])\n        y = df[target_column]\n        \n        numeric_cols = get_numeric_columns(X)\n        if not numeric_cols:\n            st.error(\"‚ùå No numeric columns for features\")\n            return {}\n        \n        X = X[numeric_cols]\n        X = X.fillna(X.mean())\n        \n        if not pd.api.types.is_numeric_dtype(y):\n            st.error(f\"‚ùå Target column must be numeric for regression\")\n            return {}\n        \n        y = y.fillna(y.mean())\n        \n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n        \n        if models is None:\n            models = ['random_forest', 'ridge']\n            if XGBOOST_AVAILABLE:\n                models.append('xgboost')\n        \n        results = {}\n        \n        for model_name in models:\n            try:\n                if model_name == 'random_forest':\n                    model = RandomForestRegressor(n_estimators=100, random_state=42)\n                elif model_name == 'xgboost' and XGBOOST_AVAILABLE:\n                    model = xgb.XGBRegressor(n_estimators=100, random_state=42)\n                elif model_name == 'ridge':\n                    model = Ridge(alpha=1.0, random_state=42)\n                elif model_name == 'lasso':\n                    model = Lasso(alpha=1.0, random_state=42)\n                else:\n                    continue\n                \n                model.fit(X_train, y_train)\n                y_pred = model.predict(X_test)\n                \n                metrics = {\n                    'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),\n                    'mae': mean_absolute_error(y_test, y_pred),\n                    'r2': r2_score(y_test, y_pred)\n                }\n                \n                results[model_name] = {\n                    'model': model,\n                    'metrics': metrics,\n                    'predictions': y_pred.tolist()\n                }\n                \n            except Exception as e:\n                st.warning(f\"‚ö†Ô∏è {model_name} training failed: {str(e)[:50]}\")\n                continue\n        \n        return results\n        \n    except Exception as e:\n        st.error(f\"‚ùå Regression failed: {str(e)}\")\n        return {}\n\ndef perform_clustering(\n    df: pd.DataFrame,\n    n_clusters: int = 3,\n    method: str = \"kmeans\"\n) -> Dict:\n    \n    if not validate_dataframe(df, min_rows=20, operation=\"clustering\"):\n        return {}\n    \n    try:\n        numeric_cols = get_numeric_columns(df)\n        if not numeric_cols:\n            st.error(\"‚ùå No numeric columns for clustering\")\n            return {}\n        \n        X = df[numeric_cols].fillna(df[numeric_cols].mean())\n        \n        if method == \"kmeans\":\n            model = KMeans(n_clusters=n_clusters, random_state=42)\n        elif method == \"dbscan\":\n            model = DBSCAN(eps=0.5, min_samples=5)\n        else:\n            st.error(f\"‚ùå Unknown clustering method: {method}\")\n            return {}\n        \n        labels = model.fit_predict(X)\n        \n        return {\n            'labels': labels.tolist(),\n            'n_clusters': len(np.unique(labels)),\n            'model': model\n        }\n        \n    except Exception as e:\n        st.error(f\"‚ùå Clustering failed: {str(e)}\")\n        return {}\n\ndef perform_pca(df: pd.DataFrame, n_components: int = 2) -> Dict:\n    if not validate_dataframe(df, min_rows=10, operation=\"PCA\"):\n        return {}\n    \n    try:\n        numeric_cols = get_numeric_columns(df)\n        if not numeric_cols:\n            st.error(\"‚ùå No numeric columns for PCA\")\n            return {}\n        \n        X = df[numeric_cols].fillna(df[numeric_cols].mean())\n        \n        pca = PCA(n_components=min(n_components, len(numeric_cols)))\n        X_pca = pca.fit_transform(X)\n        \n        return {\n            'transformed_data': X_pca,\n            'explained_variance': pca.explained_variance_ratio_.tolist(),\n            'n_components': pca.n_components_\n        }\n        \n    except Exception as e:\n        st.error(f\"‚ùå PCA failed: {str(e)}\")\n        return {}\n\ndef get_feature_importance(model, feature_names: List[str]) -> Dict:\n    try:\n        if hasattr(model, 'feature_importances_'):\n            importances = model.feature_importances_\n            importance_dict = {name: float(imp) for name, imp in zip(feature_names, importances)}\n            return dict(sorted(importance_dict.items(), key=lambda x: x[1], reverse=True))\n        elif hasattr(model, 'coef_'):\n            importances = np.abs(model.coef_).flatten()\n            importance_dict = {name: float(imp) for name, imp in zip(feature_names, importances)}\n            return dict(sorted(importance_dict.items(), key=lambda x: x[1], reverse=True))\n        else:\n            return {}\n    except Exception as e:\n        return {}\n","size_bytes":9389},"utils/__init__.py":{"content":"","size_bytes":0},"attached_assets/README_1763157388116.md":{"content":"# ü§ñ AI Data Analysis Platform\n### By Muhammad Irbabul Salas\n\nComprehensive AI-powered data analysis platform with Gemini 2.5, automated machine learning, interactive dashboards, and advanced analytics.\n\n![Platform](https://img.shields.io/badge/Platform-Streamlit-red)\n![Python](https://img.shields.io/badge/Python-3.11+-blue)\n![AI](https://img.shields.io/badge/AI-Gemini_2.5-green)\n![License](https://img.shields.io/badge/License-MIT-yellow)\n\n---\n\n## ‚ú® Features\n\n### üéØ Core Capabilities\n- **AI Chat Assistant** - Powered by Gemini 2.5 Flash with function calling\n- **Automated Machine Learning** - 10+ algorithms with auto-comparison\n- **Interactive Dashboards** - Multi-page responsive interface\n- **Text Analytics** - Sentiment analysis, topic modeling, word clouds\n- **Comprehensive Export** - PDF, Excel, models, Jupyter notebooks\n\n### üìä Data Analysis\n- Multi-format upload (CSV, Excel, JSON, Parquet, TSV)\n- Automatic data profiling & quality assessment  \n- Advanced cleaning with multiple strategies\n- Statistical tests & correlation analysis\n- Feature importance & SHAP values\n\n### üé® User Experience\n- Responsive design (mobile/tablet/desktop)\n- Dark/Light mode toggle\n- Interactive onboarding & help system\n- Sample datasets for instant testing\n- Rate limiting for free API tier\n\n---\n\n## üöÄ Quick Start\n\n### Prerequisites\n- Python 3.11+\n- Gemini API Key ([Get Free Key](https://aistudio.google.com/app/apikey))\n\n### Installation\n\n1. **Clone or download this project**\n\n2. **Install dependencies**\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n3. **Set up Gemini API Key**\n   - Get free API key from: https://aistudio.google.com/app/apikey\n   - Add to Replit Secrets with key: `GEMINI_API_KEY`\n   - Or set environment variable locally\n\n4. **Run application**\n   ```bash\n   streamlit run app.py --server.port 5000\n   ```\n\n5. **Open browser**\n   ```\n   http://localhost:5000\n   ```\n\n---\n\n## üìñ User Guide\n\n### Uploading Data\n1. Click sidebar \"Upload Data\"\n2. Select file (CSV, Excel, JSON, Parquet)\n3. Or load sample datasets to try features\n\n### AI Chat Assistant\n- Ask natural language questions about your data\n- **Rate Limit**: 1 minute between questions, 15/hour (free tier)\n- **Examples**:\n  - \"Show correlation between age and salary\"\n  - \"Train classification models to predict churn\"\n  - \"Analyze sentiment of customer reviews\"\n\n### Machine Learning\n1. Go to \"ü§ñ ML Models\" tab\n2. Select target column\n3. Choose models to train\n4. Click \"Train Models\"\n5. View metrics, confusion matrix, feature importance\n\n### Exporting Results\n- Navigate to \"üì• Export Center\"\n- Download cleaned data (CSV/Excel/JSON)\n- Export trained models (.pkl format)\n- Generate PDF reports\n\n---\n\n## üèóÔ∏è Project Structure\n\n```\nai-data-analysis/\n‚îú‚îÄ‚îÄ app.py                          # Main application\n‚îú‚îÄ‚îÄ requirements.txt                # Python dependencies\n‚îú‚îÄ‚îÄ Procfile                       # Railway deployment\n‚îú‚îÄ‚îÄ railway.json                   # Railway config\n‚îÇ\n‚îú‚îÄ‚îÄ modules/                       # Core modules\n‚îÇ   ‚îú‚îÄ‚îÄ data_processing.py         # Data loading & cleaning\n‚îÇ   ‚îú‚îÄ‚îÄ ml_models.py               # ML training & evaluation\n‚îÇ   ‚îú‚îÄ‚îÄ visualizations.py          # Chart generation\n‚îÇ   ‚îú‚îÄ‚îÄ text_analytics.py          # NLP functions\n‚îÇ   ‚îú‚îÄ‚îÄ gemini_integration.py      # AI function calling\n‚îÇ   ‚îî‚îÄ‚îÄ export_handler.py          # Export functionality\n‚îÇ\n‚îú‚îÄ‚îÄ utils/                         # Utilities\n‚îÇ   ‚îú‚îÄ‚îÄ error_handler.py           # Error management\n‚îÇ   ‚îú‚îÄ‚îÄ rate_limiter.py            # API rate limiting\n‚îÇ   ‚îî‚îÄ‚îÄ helpers.py                 # Helper functions\n‚îÇ\n‚îú‚îÄ‚îÄ assets/                        # Static files\n‚îÇ   ‚îú‚îÄ‚îÄ profile_photo.jpg          # User photo\n‚îÇ   ‚îî‚îÄ‚îÄ sample_datasets/           # Sample data\n‚îÇ\n‚îî‚îÄ‚îÄ docs/                          # Documentation\n    ‚îú‚îÄ‚îÄ DEPLOYMENT.md              # Railway deployment guide\n    ‚îî‚îÄ‚îÄ TROUBLESHOOTING.md         # Common issues\n```\n\n---\n\n## üåê Deployment to Railway\n\nSee detailed guide in [docs/DEPLOYMENT.md](docs/DEPLOYMENT.md)\n\n### Quick Steps:\n1. Push code to GitHub\n2. Connect Railway to your repo\n3. Add `GEMINI_API_KEY` to environment variables\n4. Deploy!\n\n**Estimated Cost**: ~$5/month with Railway Hobby plan\n\n---\n\n## üí∞ Cost Breakdown\n\n| Service | Free Tier | Monthly Cost |\n|---------|-----------|--------------|\n| Gemini API (Flash) | 15 req/min, 1.5K/day | **FREE** |\n| Railway | $5 credit trial | ~$5 after trial |\n| GitHub | Unlimited repos | **FREE** |\n| **Total** | | **~$5/month** |\n\n---\n\n## üîë Getting API Keys\n\n### Gemini API (Required)\n1. Visit: https://aistudio.google.com/app/apikey\n2. Login with Google account\n3. Click \"Create API Key\"\n4. Copy and save to Replit Secrets\n\n---\n\n## üéØ Features by Dashboard\n\n### üìà Overview Dashboard\n- Total rows, columns, missing values\n- Data quality score\n- Column type breakdown\n- AI-generated insights\n\n### üîç Data Profiling\n- Detailed column statistics\n- Missing values analysis\n- Correlation heatmap\n- Data cleaning interface\n\n### üìä EDA (Exploratory Data Analysis)\n- Distribution plots (histogram, box, violin)\n- Relationship analysis (scatter, line)\n- Statistical comparisons\n\n### ü§ñ ML Models\n- Classification (Random Forest, XGBoost, Logistic Regression, etc.)\n- Regression (Ridge, Lasso, Random Forest)\n- Clustering (K-Means, DBSCAN)\n- Feature importance & SHAP values\n\n### üìù Text Analytics\n- Sentiment analysis\n- Word clouds\n- N-gram analysis (bigrams, trigrams)\n- Text statistics\n\n### üì• Export Center\n- Data exports (CSV, Excel, JSON, Parquet)\n- Model exports (.pkl, .joblib)\n- PDF reports\n- Jupyter notebooks\n\n---\n\n## ‚öôÔ∏è Tech Stack\n\n**Frontend/UI:**\n- Streamlit (web framework)\n- Plotly (interactive visualizations)\n- Custom CSS (responsive design)\n\n**AI/ML:**\n- Google Gemini 2.5 (AI chat & function calling)\n- scikit-learn (traditional ML)\n- XGBoost, LightGBM (gradient boosting)\n- SHAP (model interpretability)\n\n**Data Processing:**\n- pandas (data manipulation)\n- NumPy (numerical computing)\n- NLTK, TextBlob (NLP)\n\n**Export:**\n- FPDF, ReportLab (PDF generation)\n- Joblib (model serialization)\n- NBFormat (Jupyter notebooks)\n\n---\n\n## üêõ Troubleshooting\n\n### Common Issues\n\n**Q: \"API rate limit reached\"**\nA: Wait 1 minute between questions. Free tier allows 15 requests/hour.\n\n**Q: \"File upload failed\"**\nA: Check file size (max 200MB) and format. Try converting to CSV.\n\n**Q: \"Model training failed\"**\nA: Ensure you have enough data (min 50 rows) and numeric features.\n\n**Q: \"GEMINI_API_KEY not found\"**\nA: Add API key to Replit Secrets or environment variables.\n\nSee [docs/TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md) for more.\n\n---\n\n## üìù License\n\nMIT License - Free to use, modify, and distribute.\n\n---\n\n## üë®‚Äçüíª Author\n\n**Muhammad Irbabul Salas**\n\nPlatform for automated data analysis with AI assistance.\n\n---\n\n## üôè Acknowledgments\n\n- Google Gemini AI for powerful LLM capabilities\n- Streamlit for amazing web framework\n- Open source ML libraries (scikit-learn, XGBoost, etc.)\n\n---\n\n## üìä Version\n\n**Version 1.0.0** - Initial Release (November 2025)\n\n---\n\n**Made with ‚ù§Ô∏è by Muhammad Irbabul Salas**\n\n*Powered by Gemini 2.5 Flash | Built with Streamlit*\n","size_bytes":7315},"modules/gemini_integration.py":{"content":"import os\nimport json\nimport streamlit as st\nfrom google import genai\nfrom google.genai import types\nfrom typing import Optional, List, Dict, Any\nimport sys\nsys.path.append('..')\nfrom utils.error_handler import log_error\n\napi_key = os.environ.get(\"GEMINI_API_KEY\")\nif api_key:\n    client = genai.Client(api_key=api_key)\nelse:\n    client = None\n\nAVAILABLE_FUNCTIONS = [\n    {\n        \"name\": \"profile_data\",\n        \"description\": \"Generate comprehensive data profile including statistics, data types, missing values, and quality assessment\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"include_correlations\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Include correlation analysis\"\n                },\n                \"include_distributions\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Include distribution analysis\"\n                }\n            }\n        }\n    },\n    {\n        \"name\": \"clean_data\",\n        \"description\": \"Clean dataset with various strategies for missing values, duplicates, and outliers\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"handle_missing\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"drop\", \"mean\", \"median\", \"mode\", \"knn\"],\n                    \"description\": \"Strategy for handling missing values\"\n                },\n                \"remove_duplicates\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Remove duplicate rows\"\n                },\n                \"handle_outliers\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"none\", \"iqr\", \"zscore\", \"isolation_forest\"],\n                    \"description\": \"Method for detecting/removing outliers\"\n                }\n            },\n            \"required\": [\"handle_missing\"]\n        }\n    },\n    {\n        \"name\": \"train_classification_model\",\n        \"description\": \"Train classification models (Random Forest, XGBoost, Logistic Regression, etc.)\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"target_column\": {\n                    \"type\": \"string\",\n                    \"description\": \"Name of the target column for classification\"\n                },\n                \"models\": {\n                    \"type\": \"array\",\n                    \"items\": {\n                        \"type\": \"string\",\n                        \"enum\": [\"random_forest\", \"xgboost\", \"logistic\", \"svm\", \"lightgbm\"]\n                    },\n                    \"description\": \"List of models to train\"\n                },\n                \"tune_hyperparameters\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Perform hyperparameter tuning\"\n                }\n            },\n            \"required\": [\"target_column\"]\n        }\n    },\n    {\n        \"name\": \"create_visualization\",\n        \"description\": \"Create interactive visualizations (scatter, bar, line, heatmap, etc.)\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"chart_type\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"scatter\", \"bar\", \"line\", \"histogram\", \"box\", \"heatmap\", \"violin\"],\n                    \"description\": \"Type of chart to create\"\n                },\n                \"x_column\": {\n                    \"type\": \"string\",\n                    \"description\": \"Column for x-axis\"\n                },\n                \"y_column\": {\n                    \"type\": \"string\",\n                    \"description\": \"Column for y-axis (optional for some charts)\"\n                },\n                \"color_by\": {\n                    \"type\": \"string\",\n                    \"description\": \"Column to use for color grouping\"\n                }\n            },\n            \"required\": [\"chart_type\"]\n        }\n    },\n    {\n        \"name\": \"analyze_text\",\n        \"description\": \"Perform text analytics: sentiment analysis, topic modeling, word clouds\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"text_column\": {\n                    \"type\": \"string\",\n                    \"description\": \"Column containing text data\"\n                },\n                \"tasks\": {\n                    \"type\": \"array\",\n                    \"items\": {\n                        \"type\": \"string\",\n                        \"enum\": [\"sentiment\", \"topic_modeling\", \"wordcloud\", \"ngrams\"]\n                    },\n                    \"description\": \"Text analysis tasks to perform\"\n                }\n            },\n            \"required\": [\"text_column\", \"tasks\"]\n        }\n    }\n]\n\ndef chat_with_gemini(\n    user_message: str,\n    chat_history: Optional[List[Dict]] = None,\n    context: Optional[Dict] = None,\n    max_retries: int = 3\n) -> Optional[str]:\n    if client is None:\n        return \"üîë Gemini API key not configured. Please add GEMINI_API_KEY to your secrets.\"\n    \n    try:\n        system_prompt = \"\"\"You are an expert data scientist and AI assistant helping users analyze their data.\n        \nYou can help with:\n- Data profiling and quality assessment\n- Data cleaning and preprocessing\n- Exploratory data analysis\n- Machine learning (classification, regression, clustering)\n- Text analytics and NLP\n- Data visualization\n- Statistical analysis\n\nWhen users ask for analysis, use the available functions to help them.\nBe concise, clear, and provide actionable insights.\nAlways explain results in simple, non-technical language.\n\"\"\"\n        \n        if context:\n            system_prompt += f\"\\n\\nCurrent data context: {json.dumps(context, indent=2)}\"\n        \n        messages = []\n        if chat_history:\n            for msg in chat_history[-10:]:\n                role = \"user\" if msg.get(\"role\") == \"user\" else \"model\"\n                messages.append(types.Content(role=role, parts=[types.Part(text=msg.get(\"content\", \"\"))]))\n        \n        messages.append(types.Content(role=\"user\", parts=[types.Part(text=user_message)]))\n        \n        response = client.models.generate_content(\n            model=\"gemini-2.0-flash-exp\",\n            contents=messages,\n            config=types.GenerateContentConfig(\n                system_instruction=system_prompt,\n                temperature=0.7,\n                top_p=0.95,\n                max_output_tokens=2048\n            )\n        )\n        \n        return response.text if response.text else \"I apologize, but I couldn't generate a response. Please try again.\"\n        \n    except Exception as e:\n        error_type = type(e).__name__\n        \n        if \"429\" in str(e) or \"quota\" in str(e).lower():\n            return \"üö´ API rate limit reached. Please wait for the cooldown period.\"\n        \n        elif \"network\" in str(e).lower() or \"connection\" in str(e).lower():\n            if max_retries > 0:\n                return chat_with_gemini(user_message, chat_history, context, max_retries - 1)\n            return \"‚ùå Connection error. Please check your internet connection.\"\n        \n        elif \"api_key\" in str(e).lower() or \"unauthorized\" in str(e).lower():\n            return \"üîë API key issue. Please check your Gemini API key in settings.\"\n        \n        else:\n            log_error(\"Gemini Chat\", e)\n            return f\"‚ö†Ô∏è AI assistant temporarily unavailable. Error: {error_type}\"\n\ndef get_data_context(df) -> Dict:\n    if df is None or df.empty:\n        return {}\n    \n    return {\n        \"rows\": len(df),\n        \"columns\": len(df.columns),\n        \"column_names\": df.columns.tolist()[:20],\n        \"numeric_columns\": df.select_dtypes(include=['number']).columns.tolist()[:10],\n        \"categorical_columns\": df.select_dtypes(include=['object']).columns.tolist()[:10],\n        \"missing_values\": int(df.isnull().sum().sum()),\n        \"duplicates\": int(df.duplicated().sum())\n    }\n\ndef generate_insights(df, analysis_type: str = \"general\") -> str:\n    try:\n        context = get_data_context(df)\n        \n        if analysis_type == \"general\":\n            prompt = f\"\"\"Analyze this dataset and provide 3-5 key insights:\n            \nDataset info:\n- {context['rows']} rows, {context['columns']} columns\n- Columns: {', '.join(context['column_names'][:10])}\n- Missing values: {context['missing_values']}\n- Duplicates: {context['duplicates']}\n\nProvide actionable insights in bullet points.\"\"\"\n        \n        elif analysis_type == \"quality\":\n            prompt = f\"\"\"Assess the data quality of this dataset:\n            \n- Missing values: {context['missing_values']} ({(context['missing_values']/(context['rows']*context['columns'])*100):.1f}%)\n- Duplicates: {context['duplicates']}\n\nProvide quality assessment and recommendations.\"\"\"\n        \n        else:\n            prompt = f\"Analyze this dataset with {context['rows']} rows and {context['columns']} columns.\"\n        \n        response = chat_with_gemini(prompt, context=context)\n        return response or \"Unable to generate insights at this time.\"\n        \n    except Exception as e:\n        log_error(\"Generate Insights\", e)\n        return \"Unable to generate insights. Please try manual analysis.\"\n","size_bytes":9176},"modules/data_processing.py":{"content":"import pandas as pd\nimport numpy as np\nimport streamlit as st\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\nfrom typing import Tuple, Dict, List, Optional\nimport sys\nsys.path.append('..')\nfrom utils.error_handler import safe_execute, validate_dataframe\nfrom utils.helpers import get_numeric_columns, get_categorical_columns, calculate_data_quality_score\n\ndef load_data_from_file(uploaded_file) -> Optional[pd.DataFrame]:\n    if uploaded_file is None:\n        return None\n    \n    try:\n        file_extension = uploaded_file.name.split('.')[-1].lower()\n        \n        file_size_mb = uploaded_file.size / (1024 * 1024)\n        if file_size_mb > 200:\n            st.error(f\"‚ùå File too large: {file_size_mb:.1f}MB (Max: 200MB)\")\n            return None\n        \n        if file_extension == 'csv':\n            df = pd.read_csv(uploaded_file)\n        elif file_extension in ['xlsx', 'xls']:\n            df = pd.read_excel(uploaded_file)\n        elif file_extension == 'json':\n            df = pd.read_json(uploaded_file)\n        elif file_extension == 'parquet':\n            df = pd.read_parquet(uploaded_file)\n        elif file_extension == 'tsv' or file_extension == 'txt':\n            df = pd.read_csv(uploaded_file, sep='\\t')\n        else:\n            st.error(f\"‚ùå Unsupported file type: .{file_extension}\")\n            return None\n        \n        if df.empty:\n            st.warning(\"üì≠ File is empty\")\n            return None\n        \n        st.success(f\"‚úÖ Loaded {len(df):,} rows, {len(df.columns)} columns\")\n        return df\n        \n    except pd.errors.EmptyDataError:\n        st.error(\"‚ùå Empty file\")\n        return None\n    except pd.errors.ParserError as e:\n        st.error(f\"‚ùå File format error: {str(e)[:100]}\")\n        return None\n    except Exception as e:\n        st.error(f\"‚ö†Ô∏è Upload failed: {type(e).__name__}\")\n        return None\n\ndef profile_data(df: pd.DataFrame) -> Dict:\n    if not validate_dataframe(df, min_rows=1, operation=\"profiling\"):\n        return {}\n    \n    profile = {\n        'basic_info': {\n            'rows': len(df),\n            'columns': len(df.columns),\n            'memory_usage': df.memory_usage(deep=True).sum() / 1024**2,\n            'duplicates': df.duplicated().sum()\n        },\n        'column_info': {},\n        'missing_values': {},\n        'data_types': {},\n        'quality_score': calculate_data_quality_score(df)\n    }\n    \n    for col in df.columns:\n        profile['column_info'][col] = {\n            'dtype': str(df[col].dtype),\n            'missing': int(df[col].isnull().sum()),\n            'missing_pct': round((df[col].isnull().sum() / len(df)) * 100, 2),\n            'unique': int(df[col].nunique()),\n            'unique_pct': round((df[col].nunique() / len(df)) * 100, 2)\n        }\n        \n        if df[col].dtype in ['int64', 'float64']:\n            profile['column_info'][col].update({\n                'mean': float(df[col].mean()) if not df[col].isnull().all() else None,\n                'median': float(df[col].median()) if not df[col].isnull().all() else None,\n                'std': float(df[col].std()) if not df[col].isnull().all() else None,\n                'min': float(df[col].min()) if not df[col].isnull().all() else None,\n                'max': float(df[col].max()) if not df[col].isnull().all() else None\n            })\n    \n    profile['missing_values'] = {\n        col: int(df[col].isnull().sum()) \n        for col in df.columns if df[col].isnull().sum() > 0\n    }\n    \n    profile['data_types'] = {\n        'numeric': len(get_numeric_columns(df)),\n        'categorical': len(get_categorical_columns(df)),\n        'datetime': len(df.select_dtypes(include=['datetime64']).columns)\n    }\n    \n    return profile\n\ndef clean_data(\n    df: pd.DataFrame,\n    handle_missing: str = \"mean\",\n    remove_duplicates: bool = True,\n    handle_outliers: str = \"none\"\n) -> Tuple[pd.DataFrame, Dict]:\n    if not validate_dataframe(df, min_rows=1, operation=\"cleaning\"):\n        return df, {}\n    \n    df_clean = df.copy()\n    report = {\n        'missing_handled': 0,\n        'duplicates_removed': 0,\n        'outliers_handled': 0,\n        'actions': []\n    }\n    \n    if remove_duplicates:\n        initial_rows = len(df_clean)\n        df_clean = df_clean.drop_duplicates()\n        removed = initial_rows - len(df_clean)\n        report['duplicates_removed'] = removed\n        if removed > 0:\n            report['actions'].append(f\"Removed {removed} duplicate rows\")\n    \n    numeric_cols = get_numeric_columns(df_clean)\n    \n    if handle_missing != \"drop\":\n        if handle_missing == \"mean\" and numeric_cols:\n            for col in numeric_cols:\n                if df_clean[col].isnull().sum() > 0:\n                    mean_val = df_clean[col].mean()\n                    df_clean[col].fillna(mean_val, inplace=True)\n                    report['missing_handled'] += 1\n            report['actions'].append(f\"Filled missing values with mean for {report['missing_handled']} columns\")\n        \n        elif handle_missing == \"median\" and numeric_cols:\n            for col in numeric_cols:\n                if df_clean[col].isnull().sum() > 0:\n                    median_val = df_clean[col].median()\n                    df_clean[col].fillna(median_val, inplace=True)\n                    report['missing_handled'] += 1\n            report['actions'].append(f\"Filled missing values with median for {report['missing_handled']} columns\")\n        \n        elif handle_missing == \"mode\":\n            for col in df_clean.columns:\n                if df_clean[col].isnull().sum() > 0:\n                    mode_val = df_clean[col].mode()[0] if not df_clean[col].mode().empty else None\n                    if mode_val is not None:\n                        df_clean[col].fillna(mode_val, inplace=True)\n                        report['missing_handled'] += 1\n            report['actions'].append(f\"Filled missing values with mode for {report['missing_handled']} columns\")\n    else:\n        initial_rows = len(df_clean)\n        df_clean = df_clean.dropna()\n        removed = initial_rows - len(df_clean)\n        report['missing_handled'] = removed\n        if removed > 0:\n            report['actions'].append(f\"Dropped {removed} rows with missing values\")\n    \n    if handle_outliers == \"iqr\" and numeric_cols:\n        outliers_removed = 0\n        for col in numeric_cols:\n            Q1 = df_clean[col].quantile(0.25)\n            Q3 = df_clean[col].quantile(0.75)\n            IQR = Q3 - Q1\n            lower_bound = Q1 - 1.5 * IQR\n            upper_bound = Q3 + 1.5 * IQR\n            \n            initial_len = len(df_clean)\n            df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n            outliers_removed += initial_len - len(df_clean)\n        \n        report['outliers_handled'] = outliers_removed\n        if outliers_removed > 0:\n            report['actions'].append(f\"Removed {outliers_removed} outlier rows using IQR method\")\n    \n    return df_clean, report\n\ndef encode_categorical(df: pd.DataFrame, method: str = \"onehot\") -> pd.DataFrame:\n    df_encoded = df.copy()\n    categorical_cols = get_categorical_columns(df_encoded)\n    \n    if not categorical_cols:\n        return df_encoded\n    \n    try:\n        if method == \"onehot\":\n            df_encoded = pd.get_dummies(df_encoded, columns=categorical_cols, drop_first=True)\n        elif method == \"label\":\n            le = LabelEncoder()\n            for col in categorical_cols:\n                df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n        \n        return df_encoded\n    except Exception as e:\n        st.warning(f\"‚ö†Ô∏è Encoding failed: {str(e)}\")\n        return df\n\ndef scale_features(df: pd.DataFrame, method: str = \"standard\", columns: Optional[List[str]] = None) -> pd.DataFrame:\n    df_scaled = df.copy()\n    \n    if columns is None:\n        columns = get_numeric_columns(df_scaled)\n    \n    if not columns:\n        return df_scaled\n    \n    try:\n        if method == \"standard\":\n            scaler = StandardScaler()\n        elif method == \"minmax\":\n            scaler = MinMaxScaler()\n        else:\n            return df_scaled\n        \n        df_scaled[columns] = scaler.fit_transform(df_scaled[columns])\n        return df_scaled\n    except Exception as e:\n        st.warning(f\"‚ö†Ô∏è Scaling failed: {str(e)}\")\n        return df\n","size_bytes":8410},"modules/__init__.py":{"content":"","size_bytes":0},"attached_assets/DEPLOYMENT_1763157388117.md":{"content":"# üöÄ Railway Deployment Guide - Complete Tutorial\n\n**AI Data Analysis Platform by Muhammad Irbabul Salas**\n\n---\n\n## üìã Pre-Deployment Checklist\n\nBefore deploying to Railway, ensure you have:\n- ‚úÖ GitHub account\n- ‚úÖ Railway account (sign up at https://railway.app)\n- ‚úÖ Gemini API key (from https://aistudio.google.com/app/apikey)\n- ‚úÖ Code pushed to GitHub repository\n\n---\n\n## üîë Step 1: Get Gemini API Key (5 minutes)\n\n1. Visit: **https://aistudio.google.com/app/apikey**\n2. Login with your Google account\n3. Click **\"Create API Key\"**\n4. Copy the generated API key\n5. Save it securely (you'll need it in Step 4)\n\n**Free Tier Limits:**\n- 15 requests per minute\n- 1,500 requests per day\n- 100% FREE forever for Gemini Flash\n\n---\n\n## üì¶ Step 2: Push Code to GitHub\n\n```bash\n# Initialize git (if not already done)\ngit init\n\n# Add all files\ngit add .\n\n# Commit changes\ngit commit -m \"Initial commit - AI Data Analysis Platform\"\n\n# Create repository on GitHub, then:\ngit remote add origin https://github.com/YOUR_USERNAME/YOUR_REPO_NAME.git\n\n# Push to GitHub\ngit branch -M main\ngit push -u origin main\n```\n\n---\n\n## üöÇ Step 3: Create Railway Project\n\n1. Go to **https://railway.app/**\n2. Click **\"Start a New Project\"**\n3. Click **\"Deploy from GitHub repo\"**\n4. **Authorize Railway** to access your GitHub\n5. **Select your repository** from the list\n6. Railway will automatically detect the project\n\n---\n\n## ‚öôÔ∏è Step 4: Configure Environment Variables\n\nThis is **CRITICAL** for the app to work!\n\n1. In Railway dashboard, click your project\n2. Go to **\"Variables\"** tab\n3. Click **\"+ New Variable\"**\n4. Add the following:\n\n```\nVariable Name: GEMINI_API_KEY\nValue: [paste your Gemini API key from Step 1]\n```\n\n**DO NOT** add quotes around the API key!\n\n---\n\n## üîß Step 5: Configure Deployment Settings\n\n1. Go to **\"Settings\"** tab\n2. Scroll to **\"Deploy\"** section\n3. Ensure **\"Start Command\"** is:\n   ```\n   streamlit run app.py --server.port=$PORT --server.address=0.0.0.0 --server.headless=true\n   ```\n\n4. Set **\"Restart Policy\"**: **ON_FAILURE**\n5. Set **\"Max Retries\"**: **10**\n\n---\n\n## üåê Step 6: Generate Public Domain\n\n1. In Railway dashboard, go to **\"Settings\"** tab\n2. Scroll to **\"Networking\"** section  \n3. Click **\"Generate Domain\"**\n4. Railway will provide a URL like: `your-app-name.up.railway.app`\n5. Click the URL to open your deployed app!\n\n---\n\n## ‚úÖ Step 7: Verify Deployment\n\n1. Open the generated Railway URL\n2. You should see the app loading\n3. Check:\n   - ‚úÖ Header shows \"Muhammad Irbabul Salas\"\n   - ‚úÖ Profile photo appears\n   - ‚úÖ Sidebar navigation works\n   - ‚úÖ Can upload data or load sample data\n   - ‚úÖ AI chat works (respects rate limiting)\n\nIf everything works: **Congratulations!** üéâ\n\n---\n\n## üîÑ Updating Your Deployed App\n\nRailway auto-deploys when you push to GitHub:\n\n```bash\n# Make changes to your code\n# ...\n\n# Commit changes\ngit add .\ngit commit -m \"Update: [describe changes]\"\n\n# Push to GitHub\ngit push origin main\n\n# Railway automatically detects and redeploys!\n```\n\n---\n\n## üí∞ Cost Management\n\n### Free Tier (Trial)\n- Railway gives **$5 free credit**\n- Enough for ~1 month of light usage\n- Auto-sleeps when idle (free tier)\n\n### After Trial\n- **Hobby Plan**: $5/month\n- Includes $5 usage credit\n- No auto-sleep\n- Better performance\n\n### Estimated Monthly Cost\n```\nGemini API (Flash):     $0    (FREE)\nRailway Hobby:          $5    (after trial)\nGitHub:                 $0    (FREE)\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nTotal:                  ~$5/month\n```\n\n---\n\n## üé® Custom Domain (Optional)\n\nWant to use your own domain? (e.g., `dataanalysis.yourdomain.com`)\n\n1. Buy a domain from Namecheap, GoDaddy, etc.\n2. In Railway, go to **Settings ‚Üí Networking**\n3. Click **\"Custom Domain\"**\n4. Enter your domain\n5. Update DNS records at your domain provider:\n   ```\n   Type: CNAME\n   Name: dataanalysis (or @)\n   Value: your-app.up.railway.app\n   TTL: 3600\n   ```\n6. Wait 5-30 minutes for DNS propagation\n7. Your app is now live at your custom domain!\n\n**SSL/HTTPS**: Railway provides this automatically for FREE ‚úÖ\n\n---\n\n## üìä Monitoring & Logs\n\n### View Logs\n1. Railway Dashboard ‚Üí Your Project\n2. Click **\"Deployments\"** tab\n3. Select latest deployment\n4. Click **\"View Logs\"**\n5. Real-time logs appear\n\n### Metrics\n1. Go to **\"Metrics\"** tab\n2. View:\n   - CPU usage\n   - Memory usage\n   - Network traffic\n   - Request count\n\n---\n\n## üêõ Troubleshooting\n\n### Issue: Build Failed\n\n**Error**: `Cannot find requirements.txt`\n\n**Solution**: Ensure `Procfile` and `railway.json` are in root directory\n\n---\n\n### Issue: App Won't Start\n\n**Error**: `Application error` or 5xx error\n\n**Solution**:\n1. Check logs for specific error\n2. Verify `GEMINI_API_KEY` is set correctly\n3. Ensure PORT variable is used correctly\n4. Restart deployment\n\n---\n\n### Issue: GEMINI_API_KEY Not Working\n\n**Error**: `API key invalid` or `Unauthorized`\n\n**Solution**:\n1. Get new API key from Google AI Studio\n2. Update Railway environment variable\n3. Redeploy\n\n---\n\n### Issue: Rate Limit Errors\n\n**Error**: `429 Too Many Requests`\n\n**Solution**: This is expected! App implements:\n- 1 minute cooldown between requests\n- 15 requests per hour limit\n- Visual countdown timer\n\nUsers will see countdown and can continue using other features.\n\n---\n\n## üîí Security Best Practices\n\n1. ‚úÖ **Never** commit API keys to GitHub\n2. ‚úÖ Always use Railway environment variables\n3. ‚úÖ Use `.env.example` for documentation only\n4. ‚úÖ Regularly rotate API keys\n5. ‚úÖ Monitor usage for unexpected spikes\n\n---\n\n## üìà Scaling Tips\n\n### For Higher Traffic:\n\n1. **Upgrade Railway Plan**:\n   - Pro Plan: $20/month (includes $20 credit)\n   - Better resources\n   - Priority support\n\n2. **Upgrade Gemini API**:\n   - Pay-as-you-go for higher limits\n   - Gemini Pro for better performance\n   - ~$0.075 per 1K tokens\n\n3. **Optimize Code**:\n   - Cache frequent queries\n   - Lazy load heavy features\n   - Optimize data processing\n\n---\n\n## ‚úÖ Post-Deployment Checklist\n\n```\n‚ñ° App accessible via Railway URL\n‚ñ° HTTPS working (padlock icon in browser)\n‚ñ° Profile photo displays correctly\n‚ñ° Upload functionality works\n‚ñ° Sample datasets load successfully\n‚ñ° AI chat responds (within rate limits)\n‚ñ° All dashboards render properly\n‚ñ° Export features work\n‚ñ° No errors in Railway logs\n‚ñ° Mobile responsive (test on phone)\n‚ñ° Dark/Light mode toggle works\n```\n\n---\n\n## üéâ Success!\n\nYour AI Data Analysis Platform is now live and accessible worldwide!\n\n**Share your deployed URL:**\n`https://your-app-name.up.railway.app`\n\n---\n\n**Questions or Issues?**\nCheck [TROUBLESHOOTING.md](TROUBLESHOOTING.md) or Railway documentation.\n\n---\n\n**Deployed by Muhammad Irbabul Salas**\n*Powered by Railway & Gemini 2.5*\n","size_bytes":6789},"main.py":{"content":"def main():\n    print(\"Hello from repl-nix-workspace!\")\n\n\nif __name__ == \"__main__\":\n    main()\n","size_bytes":96},"modules/export_handler.py":{"content":"import pandas as pd\nimport streamlit as st\nfrom fpdf import FPDF\nimport joblib\nimport json\nimport io\nfrom typing import Dict, Any, Optional\nimport sys\nsys.path.append('..')\nfrom utils.error_handler import safe_execute\n\ndef export_dataframe_csv(df: pd.DataFrame, filename: str = \"data.csv\"):\n    try:\n        csv = df.to_csv(index=False)\n        st.download_button(\n            label=\"üì• Download CSV\",\n            data=csv,\n            file_name=filename,\n            mime=\"text/csv\"\n        )\n        return True\n    except Exception as e:\n        st.error(f\"‚ùå CSV export failed: {str(e)}\")\n        return False\n\ndef export_dataframe_excel(df: pd.DataFrame, filename: str = \"data.xlsx\"):\n    try:\n        output = io.BytesIO()\n        with pd.ExcelWriter(output, engine='openpyxl') as writer:\n            df.to_excel(writer, index=False, sheet_name='Data')\n        output.seek(0)\n        \n        st.download_button(\n            label=\"üì• Download Excel\",\n            data=output,\n            file_name=filename,\n            mime=\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n        )\n        return True\n    except Exception as e:\n        st.error(f\"‚ùå Excel export failed: {str(e)}\")\n        return False\n\ndef export_dataframe_json(df: pd.DataFrame, filename: str = \"data.json\"):\n    try:\n        json_str = df.to_json(orient='records', indent=2)\n        st.download_button(\n            label=\"üì• Download JSON\",\n            data=json_str,\n            file_name=filename,\n            mime=\"application/json\"\n        )\n        return True\n    except Exception as e:\n        st.error(f\"‚ùå JSON export failed: {str(e)}\")\n        return False\n\ndef export_model(model: Any, filename: str = \"model.pkl\"):\n    try:\n        model_bytes = io.BytesIO()\n        joblib.dump(model, model_bytes)\n        model_bytes.seek(0)\n        \n        st.download_button(\n            label=\"üì• Download Model (.pkl)\",\n            data=model_bytes,\n            file_name=filename,\n            mime=\"application/octet-stream\"\n        )\n        return True\n    except Exception as e:\n        st.error(f\"‚ùå Model export failed: {str(e)}\")\n        return False\n\ndef export_metrics_report(metrics: Dict, filename: str = \"metrics.json\"):\n    try:\n        json_str = json.dumps(metrics, indent=2)\n        st.download_button(\n            label=\"üì• Download Metrics (JSON)\",\n            data=json_str,\n            file_name=filename,\n            mime=\"application/json\"\n        )\n        return True\n    except Exception as e:\n        st.error(f\"‚ùå Metrics export failed: {str(e)}\")\n        return False\n\ndef generate_pdf_report(\n    title: str,\n    sections: Dict[str, str],\n    filename: str = \"report.pdf\"\n):\n    try:\n        pdf = FPDF()\n        pdf.add_page()\n        \n        pdf.set_font(\"Arial\", \"B\", 16)\n        pdf.cell(0, 10, title, ln=True, align='C')\n        pdf.ln(10)\n        \n        pdf.set_font(\"Arial\", \"\", 12)\n        for section_title, content in sections.items():\n            pdf.set_font(\"Arial\", \"B\", 14)\n            pdf.cell(0, 10, section_title, ln=True)\n            pdf.set_font(\"Arial\", \"\", 11)\n            pdf.multi_cell(0, 5, content)\n            pdf.ln(5)\n        \n        pdf_bytes = pdf.output(dest='S').encode('latin-1')\n        \n        st.download_button(\n            label=\"üì• Download PDF Report\",\n            data=pdf_bytes,\n            file_name=filename,\n            mime=\"application/pdf\"\n        )\n        return True\n    except Exception as e:\n        st.error(f\"‚ùå PDF generation failed: {str(e)}\")\n        return False\n\ndef create_export_center(df: Optional[pd.DataFrame] = None, models: Optional[Dict] = None):\n    st.subheader(\"üì¶ Export Center\")\n    \n    col1, col2 = st.columns(2)\n    \n    with col1:\n        st.write(\"**üìä Data Exports**\")\n        if df is not None and not df.empty:\n            export_dataframe_csv(df, \"cleaned_data.csv\")\n            export_dataframe_excel(df, \"data_analysis.xlsx\")\n            export_dataframe_json(df, \"data.json\")\n        else:\n            st.info(\"Upload data to enable exports\")\n    \n    with col2:\n        st.write(\"**ü§ñ Model Exports**\")\n        if models and len(models) > 0:\n            for model_name, model_data in models.items():\n                if 'model' in model_data:\n                    export_model(model_data['model'], f\"{model_name}_model.pkl\")\n                if 'metrics' in model_data:\n                    export_metrics_report(model_data['metrics'], f\"{model_name}_metrics.json\")\n        else:\n            st.info(\"Train models to enable exports\")\n","size_bytes":4576},"utils/helpers.py":{"content":"import streamlit as st\nimport pandas as pd\nimport numpy as np\nfrom typing import Optional, List, Dict, Any\n\ndef format_number(num: float, decimals: int = 2) -> str:\n    if num >= 1_000_000:\n        return f\"{num/1_000_000:.{decimals}f}M\"\n    elif num >= 1_000:\n        return f\"{num/1_000:.{decimals}f}K\"\n    else:\n        return f\"{num:.{decimals}f}\"\n\ndef get_numeric_columns(df: pd.DataFrame) -> List[str]:\n    return df.select_dtypes(include=[np.number]).columns.tolist()\n\ndef get_categorical_columns(df: pd.DataFrame) -> List[str]:\n    return df.select_dtypes(include=['object', 'category']).columns.tolist()\n\ndef get_datetime_columns(df: pd.DataFrame) -> List[str]:\n    return df.select_dtypes(include=['datetime64']).columns.tolist()\n\ndef calculate_data_quality_score(df: pd.DataFrame) -> float:\n    if df is None or df.empty:\n        return 0.0\n    \n    total_cells = df.shape[0] * df.shape[1]\n    if total_cells == 0:\n        return 0.0\n    \n    missing_score = (1 - df.isnull().sum().sum() / total_cells) * 0.3\n    \n    duplicates = df.duplicated().sum()\n    duplicate_score = (1 - duplicates / len(df)) * 0.2\n    \n    numeric_cols = get_numeric_columns(df)\n    outlier_score = 0.25\n    if numeric_cols:\n        outlier_count = 0\n        for col in numeric_cols:\n            Q1 = df[col].quantile(0.25)\n            Q3 = df[col].quantile(0.75)\n            IQR = Q3 - Q1\n            outliers = ((df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))).sum()\n            outlier_count += outliers\n        outlier_score = (1 - min(outlier_count / len(df), 1)) * 0.25\n    \n    consistency_score = 0.25\n    \n    total_score = (missing_score + duplicate_score + outlier_score + consistency_score) * 100\n    return round(total_score, 1)\n\ndef safe_get_session_state(key: str, default: Any = None) -> Any:\n    return st.session_state.get(key, default)\n\ndef set_session_state(key: str, value: Any):\n    st.session_state[key] = value\n\ndef initialize_session_state():\n    defaults = {\n        'uploaded_data': None,\n        'cleaned_data': None,\n        'chat_history': [],\n        'analysis_results': {},\n        'trained_models': {},\n        'current_page': 'üìà Overview',\n        'show_onboarding': True,\n        'theme': 'light'\n    }\n    \n    for key, default_value in defaults.items():\n        if key not in st.session_state:\n            st.session_state[key] = default_value\n\ndef get_column_info(df: pd.DataFrame) -> Dict[str, Dict]:\n    info = {}\n    for col in df.columns:\n        info[col] = {\n            'dtype': str(df[col].dtype),\n            'missing': df[col].isnull().sum(),\n            'missing_pct': (df[col].isnull().sum() / len(df)) * 100,\n            'unique': df[col].nunique(),\n            'sample_values': df[col].dropna().head(3).tolist()\n        }\n    return info\n\ndef download_button(data, filename: str, label: str, mime_type: str = \"text/csv\"):\n    st.download_button(\n        label=label,\n        data=data,\n        file_name=filename,\n        mime=mime_type\n    )\n\ndef show_data_preview(df: pd.DataFrame, title: str = \"Data Preview\", rows: int = 5):\n    st.subheader(title)\n    st.dataframe(df.head(rows), use_container_width=True)\n    st.caption(f\"Showing {min(rows, len(df))} of {len(df):,} rows\")\n","size_bytes":3234},"utils/error_handler.py":{"content":"import logging\nimport streamlit as st\nfrom datetime import datetime\nfrom typing import Callable, Any, Optional\n\nlogging.basicConfig(\n    filename='app_errors.log',\n    level=logging.ERROR,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\ndef log_error(feature_name: str, error: Exception, user_context: Optional[dict] = None) -> str:\n    error_info = {\n        'timestamp': datetime.now().isoformat(),\n        'feature': feature_name,\n        'error_type': type(error).__name__,\n        'error_message': str(error),\n        'user_context': user_context or {}\n    }\n    \n    logging.error(f\"Feature Error: {error_info}\")\n    error_id = f\"ERR-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n    return error_id\n\ndef safe_execute(feature_name: str, func: Callable, *args, **kwargs) -> Any:\n    try:\n        return func(*args, **kwargs)\n    except ValueError as e:\n        st.error(f\"\"\"\n        ‚ùå **{feature_name} - Data Format Issue**\n        \n        {str(e)}\n        \n        **Solutions:**\n        ‚Ä¢ Check data types are correct\n        ‚Ä¢ Remove special characters\n        ‚Ä¢ Ensure numeric columns contain only numbers\n        \n        [üîß Try Auto-fix] [üìñ Learn More]\n        \"\"\")\n        log_error(feature_name, e)\n        return None\n    except KeyError as e:\n        st.error(f\"\"\"\n        ‚ùå **{feature_name} - Column Not Found**\n        \n        Column {str(e)} doesn't exist in the dataset.\n        \n        **Solutions:**\n        ‚Ä¢ Check column name spelling\n        ‚Ä¢ View available columns\n        ‚Ä¢ Reload your data\n        \n        [üìã Show Columns]\n        \"\"\")\n        log_error(feature_name, e)\n        return None\n    except MemoryError as e:\n        st.error(f\"\"\"\n        ‚ùå **{feature_name} - Memory Limit**\n        \n        Dataset is too large for this operation.\n        \n        **Solutions:**\n        ‚Ä¢ Use data sampling (analyze subset)\n        ‚Ä¢ Remove unnecessary columns\n        ‚Ä¢ Export to Parquet format\n        \n        [üìâ Sample 10% of Data]\n        \"\"\")\n        log_error(feature_name, e)\n        return None\n    except Exception as e:\n        error_id = log_error(feature_name, e)\n        st.error(f\"\"\"\n        ‚ö†Ô∏è **{feature_name} Unavailable**\n        \n        This feature encountered an issue, but other features still work!\n        \n        Error ID: `{error_id}`\n        Error type: {type(e).__name__}\n        \n        **You can still:**\n        ‚Ä¢ Try other features\n        ‚Ä¢ Reload the page\n        ‚Ä¢ Contact support with error ID\n        \n        [üîÑ Retry] [üìß Report Issue]\n        \"\"\")\n        return None\n\ndef validate_dataframe(df, min_rows: int = 10, operation: str = \"analysis\") -> bool:\n    if df is None or df.empty:\n        st.warning(\"\"\"\n        üì≠ **No data loaded**\n        \n        Please upload a dataset first!\n        \n        [üì§ Upload Data] [üìù Try Sample Dataset]\n        \"\"\")\n        return False\n    \n    if len(df) < min_rows:\n        st.warning(f\"\"\"\n        ‚ö†Ô∏è **Dataset too small**\n        \n        You need at least {min_rows} rows for {operation}.\n        Current: {len(df)} rows\n        \n        [üì§ Upload larger dataset]\n        \"\"\")\n        return False\n    \n    return True\n\ndef show_error_recovery(error_type: str):\n    recovery_guide = {\n        'ValueError': {\n            'message': 'Data format issue',\n            'steps': [\n                '1. Check your data has correct types',\n                '2. Remove special characters',\n                '3. Ensure numeric columns contain only numbers'\n            ]\n        },\n        'KeyError': {\n            'message': 'Column not found',\n            'steps': [\n                '1. Verify column name spelling',\n                '2. Check for extra spaces',\n                '3. Reload your data'\n            ]\n        },\n        'MemoryError': {\n            'message': 'Dataset too large',\n            'steps': [\n                '1. Use data sampling',\n                '2. Remove unnecessary columns',\n                '3. Export to Parquet format'\n            ]\n        }\n    }\n    \n    guide = recovery_guide.get(error_type, {\n        'message': 'Unexpected error',\n        'steps': [\n            '1. Refresh the page',\n            '2. Re-upload your data',\n            '3. Contact support if persists'\n        ]\n    })\n    \n    st.warning(f\"**{guide['message']}**\")\n    for step in guide['steps']:\n        st.write(step)\n","size_bytes":4420},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"fpdf2>=2.8.5\",\n    \"google-genai>=1.50.1\",\n    \"google-generativeai>=0.8.5\",\n    \"joblib>=1.5.2\",\n    \"lightgbm>=4.6.0\",\n    \"matplotlib>=3.10.7\",\n    \"numpy>=2.3.4\",\n    \"pandas>=2.3.3\",\n    \"plotly>=6.4.0\",\n    \"scikit-learn>=1.7.2\",\n    \"seaborn>=0.13.2\",\n    \"statsmodels>=0.14.5\",\n    \"streamlit>=1.51.0\",\n    \"textblob>=0.19.0\",\n    \"wordcloud>=1.9.4\",\n    \"xgboost>=3.1.1\",\n]\n\n[[tool.uv.index]]\nexplicit = true\nname = \"pytorch-cpu\"\nurl = \"https://download.pytorch.org/whl/cpu\"\n\n[tool.uv.sources]\nAA-module = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nABlooper = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nAnalysisG = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nAutoRAG = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nBERTeam = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nBxTorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nByaldi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCALM-Pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCOPEX-high-rate-compression-quality-metrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCityLearn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCoCa-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCoLT5-attention = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nComfyUI-EasyNodes = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCrawl4AI = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDALL-E = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDI-toolkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDatasetRising = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDeepCache = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDeepMatter = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDraugr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nESRNN = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nEn-transformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nExpoSeq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nFLAML = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nFSRS-Optimizer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nGANDLF = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nGQLAlchemy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nGhostScan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nGraKeL = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nHEBO = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nIOPaint = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nISLP = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nInvokeAI = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nJAEN = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nKapoorLabs-Lightning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nLightAutoML = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nLingerGRN = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nMMEdu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nMRzeroCore = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nModeva = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nNeuralFoil = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nNiMARE = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nNinjaTools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nOpenHosta = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nOpenNMT-py = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPOT = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPVNet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPaLM-rlhf-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPepperPepper = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPiML = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPoutyne = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nQNCP = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nRAGatouille = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nRareGO = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nRealtimeSTT = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nRelevanceAI-Workflows-Core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nResemblyzer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nScandEval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nSimba-UW-tf-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nSwissArmyTransformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nTPOT = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nTTS = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nTorchCRF = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nTotalSegmentator = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nUtilsRL = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nWhisperSpeech = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nXAISuite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\na-unet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\na5dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naccelerate = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naccelerated-scan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naccern-xyme = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nachatbot = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nacids-rave = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nactorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nacvl-utils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadabelief-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadam-atan2-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadan-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadapters = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadmin-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadtoolbox = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadversarial-robustness-toolbox = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naeiou = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naeon = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nafricanwhisper = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nag-llama-api = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nagentdojo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nagilerl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai-edge-torch-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai-parrot = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai-python = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai-transform = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai2-olmo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai2-olmo-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai2-tango = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naicmder = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naider-chat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naider-chat-x = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naif360 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naihwkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naimodelshare = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nairllm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nairtestProject = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nairunner = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naisak = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naislib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naisquared = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naistore = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naithree = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nakasha-terminal = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalibi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalibi-detect = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalignn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nall-clip = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nallennlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nallennlp-models = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nallennlp-pvt-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nallophant = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nallosaurus = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naloy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalpaca-eval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalphafold2-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalphafold3-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalphamed-federated = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalphawave = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\namazon-braket-pennylane-plugin = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\namazon-photos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nanemoi-graphs = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nanemoi-models = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nanomalib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\napache-beam = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\napache-tvm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naperturedb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naphrodite-engine = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naqlm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narcAGI2024 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narchisound = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nargbind = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narize = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narm-pytorch-utilities = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narray-api-compat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narus = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nassert-llm-tools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nasteroid = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nasteroid-filterbanks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nastra-llm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nastrovision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\natomate2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nattacut = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naudio-diffusion-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naudio-encoders-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naudio-separator = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naudiocraft = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naudiolm-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nauralis = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nauraloss = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nauto-gptq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nautoawq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nautoawq-kernels = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n\"autogluon.multimodal\" = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n\"autogluon.tabular\" = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n\"autogluon.timeseries\" = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nautotrain-advanced = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\navdeepfake1m = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naws-fortuna = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nax-platform = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nazureml-automl-dnn-vision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nazureml-contrib-automl-dnn-forecasting = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nazureml-evaluate-mlflow = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nazureml-metrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nazureml-train-automl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nb2bTools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbackpack-for-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbalrog-nle = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbatch-face = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbatchalign = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbatchgeneratorsv2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbatchtensor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbbrl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbenchpots = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbent = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbert-score = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbertopic = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbertviz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbestOf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbetty-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbig-sleep = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbigdl-core-cpp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbigdl-core-npu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbigdl-llm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbigdl-nano = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n\"bioimageio.core\" = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbitfount = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbitsandbytes = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbittensor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbittensor-cli = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nblackboxopt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nblanc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nblindai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbm25-pt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nboltz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbotorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nboxmot = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbrainchain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbraindecode = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbrevitas = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbriton = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbrowsergym-visualwebarena = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbuzz-captions = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbyotrack = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbyzerllm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nc4v-py = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncalflops = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncame-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncamel-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncamel-tools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncannai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncaptum = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncarte-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncarvekit-colab = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncatalyst = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncausalml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncausalnex = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncausy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncbrkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncca-zoo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncdp-backend = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncellacdc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncellfinder = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncellpose = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncellxgene-census = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nchattts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nchemprop = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nchgnet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nchitra = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncircuitsvis = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncjm-yolox-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclarinpl-embeddings = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclass-resolver = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclassifier-free-guidance-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclassiq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclassy-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclean-fid = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncleanvision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclip-anytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclip-benchmark = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclip-by-openai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclip-interrogator = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclip-retrieval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncltk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclusterops = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncnocr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncnstd = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncoba = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncofi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncolbert-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncolpali-engine = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncompel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncomposabl-ray = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncomposabl-ray-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncomposabl-train = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncomposabl-train-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncomposer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncompressai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncompressed-tensors = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncompressed-tensors-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nconcrete-python = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nconfit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nconformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncontextualSpellCheck = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncontinual-inference = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncontrolnet-aux = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nconvokit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncoola = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncoqui-tts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncoqui-tts-trainer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncraft-text-detector = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncreme = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncrocodile = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncrowd-kit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncryoSPHERE = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncsle-common = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncsle-system-identification = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nctgan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncurated-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncut-cross-entropy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncvat-sdk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncybertask = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nd3rlpy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndalle-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndalle2-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndanila-lib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndanling = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndarts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndarwin-py = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndata-gradients = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndatachain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndataclass-array = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndataeval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndatarobot-drum = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndatarobotx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndatasets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndatumaro = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndctorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeep-utils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepchecks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepchem = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepctr-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepecho = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepepochs = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepforest = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeeplabcut = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepmd-kit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepmultilingualpunctuation = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepparse = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeeprobust = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepsparse = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepsparse-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepspeed = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndenoising-diffusion-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndescript-audio-codec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndescript-audiotools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndetecto = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndetoxify = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndgenerate = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndghs-imgutils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndgl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndialogy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndice-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndiffgram = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndiffq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndiffusers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndistilabel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndistrifuser = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndnikit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndocarray = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndoclayout-yolo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndocling-ibm-models = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndocquery = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndomino-code-assist = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndreamsim = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndropblock = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndruida = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndvclive = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ne2-tts-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ne2cnn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ne3nn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neasyocr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nebtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\necallisto-ng = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nedsnlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neffdet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neinx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neir-dl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neis1600 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neland = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nema-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nembedchain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nenformer-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nentmax = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nesm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nespaloma-charge = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nespnet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\netils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\netna = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nevadb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nevalscope = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nevaluate = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nexllamav2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nextractable = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nface-alignment = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfacenet-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfacexlib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfair-esm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfairseq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfairseq2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfairseq2n = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfaker-file = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfarm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfast-bert = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfast-pytorch-kmeans = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfastai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfastcore = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfastestimator-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfasttreeshap = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfedml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfelupe = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfemr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfft-conv-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfickling = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfireworks-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflair = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflashrag-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflax = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflexgen = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflgo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflopth = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflowcept = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflytekitplugins-kfpytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflytekitplugins-onnxpytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfmbench = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfocal-frequency-loss = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfoldedtensor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfractal-tasks-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfreegenius = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfreqtrade = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfschat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfunasr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfunctorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfunlbm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfunsor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngalore-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngarak = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngarf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngateloop-transformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngeffnet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngenutility = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngfpgan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngigagan-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngin-config = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nglasflow = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngliner = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngluonts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngmft = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngoogle-cloud-aiplatform = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngpforecaster = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngpt3discord = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngpytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngrad-cam = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngraph-weather = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngraphistry = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngravitorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngretel-synthetics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngsplat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nguardrails-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nguidance = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngymnasium = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhanlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhappytransformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhbutils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nheavyball = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhezar = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhf-deepali = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhf-doc-builder = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhigher = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhjxdl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhkkang-utils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhordelib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhpsv2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhuggingface-hub = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhummingbird-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhvae-backbone = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhya = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhypothesis-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nibm-metrics-plugin = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nibm-watson-machine-learning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nibm-watsonx-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nicetk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nicevision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\niden = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nidvpackage = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\niglovikov-helper-functions = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nimagededup = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nimagen-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nimaginAIry = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nimg2vec-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nincendio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninference = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninference-gpu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninfinity-emb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninfo-nce-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninfoapps-mlops-sdk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninstructlab = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninstructlab-dolomite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninstructlab-eval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninstructlab-sdg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninstructlab-training = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninvisible-watermark = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\niobm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nipex-llm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\niree-turbine = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nirisml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nirisml-tasks-azure-openai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nirisml-tasks-torchvision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nirisml-tasks-training = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nitem-matching = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nivadomed = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\njaqpotpy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\njina = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\njudo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\njunky = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nk-diffusion = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nk1lib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nk2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkappadata = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkappamodules = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkarbonn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkats = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkbnf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkedro-datasets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkeybert = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkeytotext = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkhoj = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkiui = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkonfuzio-sdk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkornia = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkornia-moons = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkraken = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkwarray = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkwimage = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlabml-nn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlagent = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlaion-clap = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlale = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlama-cleaner = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlancedb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlangcheck = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlangkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlangroid = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlangtest = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlayoutparser = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nldp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nleafmap = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nleap-ie = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nleibniz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nleptonai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nletmedoit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlhotse = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlib310 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlibpecos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlibrec-auto = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlibretranslate = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nliger-kernel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nliger-kernel-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightning-bolts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightning-fabric = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightning-habana = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightning-lite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightrag = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightweight-gan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightwood = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlinear-attention-transformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlinear-operator = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlinformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlinformer-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nliom-toolkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlion-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlit-nlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlitdata = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlitelama = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlitgpt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllama-index-embeddings-adapter = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllama-index-embeddings-clip = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllama-index-embeddings-instructor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllama-index-llms-huggingface = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllama-index-postprocessor-colbert-rerank = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllm-blender = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllm-foundry = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllm-guard = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllm-rs = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllm2vec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllmcompressor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllmlingua = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllmvm-cli = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlm-eval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlmdeploy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlmms-eval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlocal-attention = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlovely-tensors = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlpips = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlycoris-lora = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmace-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmagic-pdf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmagicsoup = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmagvit2-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmaite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmanga-ocr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmanifest-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmanipulation = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmarker-pdf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmatgl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmed-imagetools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmedaka = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmedcat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmedmnist = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmegablocks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmegatron-energon = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmemos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmeshgpt-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmetatensor-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmflux = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmia-vgg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmiditok = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nminari = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nminicons = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nml2rt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlagents = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlbench-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlcroissant = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlpfile = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlx-whisper = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmaction2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmengine = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmengine-lite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmocr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmpose = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmsegmentation = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmodeci-mdf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmodel2vec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmodelscope = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmodelspec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmonai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmonai-weekly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmonotonic-alignment-search = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmonty = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmosaicml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmosaicml-streaming = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmoshi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmteb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmtmtrain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmulti-quantization = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmyhand = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnGPT-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnaeural-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnapari = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnapatrackmater = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnara-wpe = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnatten = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnbeats-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnebulae = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnemo-toolkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneptune = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneptune-client = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnerfacc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnerfstudio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnessai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnetcal = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneural-rag = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneuralforecast = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneuralnets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneuralprophet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneuspell = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnevergrad = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnexfort = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnimblephysics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnirtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnkululeko = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnlptooltest = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnnAudio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnnodely = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnnsight = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnnunetv2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnoisereduce = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnonebot-plugin-nailongremove = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnowcasting-dataloader = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnowcasting-forecast = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnshtrainer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnuwa-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnvflare = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnvidia-modelopt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nocf-datapipes = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nocnn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nogb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nohmeow-blurr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nolive-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nomlt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nommlx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nonediff = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nonediffx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nonnx2pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nonnx2torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopacus = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopen-clip-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopen-flamingo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopen-interpreter = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenbb-terminal-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenmim = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenparse = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenunmix = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenvino-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenvino-tokenizers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenvino-xai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenwakeword = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopt-einsum-fx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptimum = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptimum-habana = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptimum-intel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptimum-neuron = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptimum-quanto = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptree = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptuna = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptuna-dashboard = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptuna-integration = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noracle-ads = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\norbit-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\notx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noutetts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noutlines = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noutlines-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npaddlenlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npai-easycv = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npandasai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npanns-inference = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npatchwork-cli = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npeft = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npegasuspy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npelutils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npenn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nperforatedai-freemium = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nperformer-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npetastorm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npfio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npgmpy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nphenolrs = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nphobos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npi-zero-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npinecone-text = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npiq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npix2tex = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npix2text = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npnnx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npolicyengine-us-data = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npolyfuzz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npomegranate = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npositional-encodings = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nprefigure = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nproduct-key-memory = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nptflops = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nptwt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npulser-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npunctuators = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npy2ls = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyabsa = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n\"pyannote.audio\" = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyawd = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyclarity = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npycox = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyfemtet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyg-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npygrinder = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyhealth = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyhf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyiqa = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npykeen = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npykeops = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npylance = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npylineaGT = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npymanopt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npymde = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npypots = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyqlib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyqtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyro-ppl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npysentimiento = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyserini = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npysr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npythainlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npython-doctr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-fid = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-forecasting = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-ignite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-kinematics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-lightning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-lightning-bolts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-metric-learning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-model-summary = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-msssim = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-pfn-extras = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-pretrained-bert = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-ranger = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-seed = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-tabnet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-tabular = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-toolbelt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-transformers-pvt-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-triton-rocm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-warmup = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-wavelets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch_optimizer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch_revgrad = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorchcv = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorchltr2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyvene = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyvespa = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nqianfan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nqibo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nqiskit-machine-learning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nqtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nquanto = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nquick-anomaly-detector = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrastervision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrastervision-pytorch-backend = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrastervision-pytorch-learner = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nray-lightning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrclip = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrealesrgan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrecbole = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrecommenders = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nredcat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nreformer-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nregex-sampler = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nreplay-rec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrerankers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nresearch-framework = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nresemble-enhance = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nresnest = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrf-clip = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrf-groundingdino = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrfconv = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrich-logger = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nring-attention-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrltrade-test = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrotary-embedding-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrsp-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrust-circuit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ns2fft = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ns3prl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ns3torchconnector = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsaferx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsafetensors = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsagemaker-huggingface-inference-toolkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsagemaker-ssh-helper = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsalesforce-lavis = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsalesforce-merlion = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsamv2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nscib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nscib-metrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nscvi-tools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsdmetrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsecretflow = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsegment-anything-hq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsegment-anything-py = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsegmentation-models-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nself-rewarding-lm-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsemantic-kernel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsemantic-router = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsenselab = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsent2vec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsentence-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsequence-model-train = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nserotiny = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsevenn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsglang = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nshap = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsilero-api-server = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsilero-vad = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsilicondiff-npu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsimclr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsimple-lama-inpainting = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsinabs = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsixdrepnet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nskforecast = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nskorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nskrl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nskt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsktime = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsktmls = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nslangtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsmartnoise-synth = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsmashed = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsmplx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsmqtk-descriptors = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsmqtk-detection = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsnntorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsnorkel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsnowflake-ml-python = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nso-vits-svc-fork = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsonusai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsony-custom-layers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsotopia = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacy-curated-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacy-experimental = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacy-huggingface-pipelines = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacy-llm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacy-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspan-marker = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspandrel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspandrel-extra-arches = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsparrow-python = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspatialdata = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspeechbrain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspeechtokenizer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspikeinterface = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspikingjelly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspotiflow = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspotpython = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspotriver = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsquirrel-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstable-baselines3 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstable-diffusion-sdkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstable-ts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstanford-stk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstanfordnlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstanza = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstartorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstreamtasks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstruct-eqtable = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstylegan2-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsupar = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsuper-gradients = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsuper-image = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsuperlinked = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsupervisely = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsurya-ocr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsvdiff-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nswarm-models = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nswarmauri = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nswarms-memory = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nswebench = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsyft = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsympytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsyne-tune = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsynthcity = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nt5 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntab-transformer-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntabpfn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntaming-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntaming-transformers-rom1504 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntaskwiz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntbparse = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntecton = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensor-parallel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensorcircuit-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensordict = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensordict-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensorizer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensorrt-llm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntexify = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntext2text = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntextattack = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntfkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nthepipe-api = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nthinc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nthingsvision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nthirdai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nthop = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntianshou = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntidy3d = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntimesfm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntimm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntipo-kgen = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntmnt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntoad = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntomesd = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntop2vec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-audiomentations = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-dct = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-delaunay = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-directml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-ema = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-encoding = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-fidelity = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-geometric = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-geopooling = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-harmonics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-kmeans = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-lr-finder = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-max-mem = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-npu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-optimi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-optimizer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-ort = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-pitch-shift = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-ppr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-pruning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-snippets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-stoi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-struct = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-tensorrt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchani = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchattacks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchaudio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchbiggraph = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchcam = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchcde = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchcfm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchcrepe = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchdata = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchdatasets-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchdiffeq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchdyn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchestra = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorcheval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorcheval-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchextractor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchfcpe = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchfun = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchfunc-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchgeo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchgeometry = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchjpeg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchlayers-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchmeta = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchmetrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchmocks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchpack = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchpippy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchpq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchprofile = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchquantlib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchrec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchrec-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchrec-nightly-cpu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchrl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchrl-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchscale = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchsde = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchseg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchserve = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchserve-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchsnapshot-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchsr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchstain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchsummaryX = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchtext = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchtnt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchtnt-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchtyping = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchutil = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchvinecopulib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchvision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchviz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchx-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchxrayvision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntotalspineseg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntracebloc-package-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntrainer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransformer-engine = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransformer-lens = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransformer-smaller-training-vocab = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransformers-domain-adaptation = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransfusion-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransparent-background = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntreescope = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntrolo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntsai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntslearn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nttspod = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntxtai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntyro = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nu8darts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nuhg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nuitestrunner-syberos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nultimate-rvc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nultralytics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nultralytics-thop = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunav = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunbabel-comet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunderthesea = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunfoldNd = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunimernet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunitorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunitxt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunsloth = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunsloth-zoo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunstructured = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunstructured-inference = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nutilsd = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nv-diffusion-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvIQA = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvectice = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvector-quantize-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvectorhub-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nversatile-audio-upscaler = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvertexai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvesin = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvgg-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvideo-representations-extractor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nviser = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvision-datasets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvisionmetrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvisu3d = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvit-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nviturka-nn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvllm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvllm-flash-attn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvocos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvollseg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwavmark = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwdoc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwhisper-live = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwhisper-timestamped = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwhisperx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwilds = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwordllama = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nworker-automate-hub = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwxbtool = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nx-clip = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nx-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nxaitk_saliency = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nxformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nxgrammar = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nxinference = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nxtts-api-server = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nyolo-poser = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nyolov5 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nyolov7-package = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nyta-general-utils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nzensvi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nzetascale = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nzuko = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n","size_bytes":90910},"app.py":{"content":"import streamlit as st\nimport pandas as pd\nimport numpy as np\nimport os\nfrom datetime import datetime\n\nfrom modules.data_processing import load_data_from_file, profile_data, clean_data\nfrom modules.ml_models import train_classification_models, train_regression_models, perform_clustering, perform_pca, get_feature_importance\nfrom modules.text_analytics import analyze_text_column, analyze_sentiment\nfrom modules.visualizations import (\n    create_scatter_plot, create_bar_chart, create_histogram, create_box_plot,\n    create_correlation_heatmap, create_line_chart, create_violin_plot,\n    create_confusion_matrix_plot, create_feature_importance_plot\n)\nfrom modules.gemini_integration import chat_with_gemini, get_data_context\nfrom modules.export_handler import create_export_center\nfrom utils.helpers import initialize_session_state, get_numeric_columns, get_categorical_columns, calculate_data_quality_score\nfrom utils.rate_limiter import initialize_rate_limiter, can_make_request, show_rate_limit_status, update_rate_limit, get_remaining_requests\nfrom utils.error_handler import safe_execute, validate_dataframe\n\nst.set_page_config(\n    page_title=\"AI Data Analysis Platform\",\n    page_icon=\"üìä\",\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\"\n)\n\nst.markdown(\"\"\"\n<style>\n    @media (max-width: 768px) {\n        section[data-testid=\"stSidebar\"] {\n            display: none;\n        }\n        section[data-testid=\"stSidebar\"][aria-expanded=\"true\"] {\n            display: block;\n            width: 100% !important;\n        }\n        .main .block-container {\n            padding: 1rem !important;\n            max-width: 100% !important;\n        }\n        div[data-testid=\"column\"] {\n            width: 100% !important;\n            margin-bottom: 1rem;\n        }\n    }\n    \n    @media (min-width: 769px) and (max-width: 1024px) {\n        section[data-testid=\"stSidebar\"] {\n            width: 250px !important;\n        }\n    }\n    \n    @media (min-width: 1025px) {\n        .main .block-container {\n            max-width: 1200px;\n            padding: 2rem 3rem;\n        }\n    }\n    \n    .stButton button {\n        width: 100%;\n    }\n    \n    div[data-testid=\"metric-container\"] {\n        background-color: #f0f2f6;\n        border: 1px solid #e0e0e0;\n        padding: 1rem;\n        border-radius: 0.5rem;\n    }\n    \n    h1, h2, h3 {\n        color: #4A90E2;\n    }\n    \n    .profile-header {\n        display: flex;\n        align-items: center;\n        padding: 1rem;\n        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n        border-radius: 10px;\n        color: white;\n        margin-bottom: 2rem;\n    }\n</style>\n\"\"\", unsafe_allow_html=True)\n\ninitialize_session_state()\ninitialize_rate_limiter()\n\ndef show_header():\n    col1, col2, col3 = st.columns([1, 6, 1])\n    \n    with col1:\n        if os.path.exists(\"assets/profile_photo.jpg\"):\n            st.image(\"assets/profile_photo.jpg\", width=80)\n    \n    with col2:\n        st.markdown(\"\"\"\n        <div style='padding-top: 10px;'>\n            <h1 style='margin:0; color: #4A90E2;'>Muhammad Irbabul Salas</h1>\n            <p style='margin:0; color: #7F8C8D; font-size: 14px;'>\n                AI-Powered Data Analysis Platform | Automated ML & Insights with Gemini 2.5\n            </p>\n        </div>\n        \"\"\", unsafe_allow_html=True)\n    \n    with col3:\n        if st.button(\"üåô\" if st.session_state.get('theme') == 'light' else \"‚òÄÔ∏è\"):\n            st.session_state.theme = 'dark' if st.session_state.get('theme') == 'light' else 'light'\n            st.rerun()\n\nshow_header()\n\nwith st.sidebar:\n    st.title(\"üìä Navigation\")\n    \n    pages = [\"üìà Overview\", \"üîç Data Profiling\", \"üìä EDA\", \"ü§ñ ML Models\", \"üöÄ Advanced ML\", \"‚è∞ Time Series\", \"üìù Text Analytics\", \"üì• Export Center\"]\n    st.session_state.current_page = st.radio(\"Go to\", pages, label_visibility=\"collapsed\")\n    \n    st.markdown(\"---\")\n    st.subheader(\"üì§ Upload Data\")\n    uploaded_file = st.file_uploader(\n        \"Upload your dataset\",\n        type=['csv', 'xlsx', 'json', 'parquet', 'txt'],\n        help=\"Supported: CSV, Excel, JSON, Parquet, TSV\"\n    )\n    \n    if uploaded_file:\n        df = load_data_from_file(uploaded_file)\n        if df is not None:\n            st.session_state.uploaded_data = df\n            st.session_state.cleaned_data = df.copy()\n    \n    if st.button(\"üìù Load Sample E-commerce Data\"):\n        try:\n            df = pd.read_csv(\"assets/sample_datasets/sample_ecommerce.csv\")\n            st.session_state.uploaded_data = df\n            st.session_state.cleaned_data = df.copy()\n            st.success(\"‚úÖ Sample data loaded!\")\n            st.rerun()\n        except:\n            st.error(\"‚ùå Sample data not found\")\n    \n    if st.button(\"üí¨ Load Sample Reviews Data\"):\n        try:\n            df = pd.read_csv(\"assets/sample_datasets/sample_reviews.csv\")\n            st.session_state.uploaded_data = df\n            st.session_state.cleaned_data = df.copy()\n            st.success(\"‚úÖ Sample reviews loaded!\")\n            st.rerun()\n        except:\n            st.error(\"‚ùå Sample data not found\")\n    \n    st.markdown(\"---\")\n    st.subheader(\"‚ùì Help & Support\")\n    \n    with st.expander(\"üìñ Quick Guide\"):\n        st.write(\"\"\"\n        **Getting Started:**\n        1. Upload your data or try sample datasets\n        2. Explore different dashboards\n        3. Ask AI for insights via chat\n        4. Export your results\n        \n        **Tips:**\n        - Use AI chat for complex analysis\n        - Download charts as PNG/HTML\n        - Save trained models for deployment\n        \"\"\")\n    \n    with st.expander(\"‚å®Ô∏è Keyboard Shortcuts\"):\n        st.write(\"\"\"\n        - `Ctrl+U`: Upload data\n        - `Ctrl+/`: Search help\n        - `Ctrl+Enter`: Send chat message\n        \"\"\")\n\ndf = st.session_state.get('cleaned_data')\n\nif st.session_state.current_page == \"üìà Overview\":\n    st.title(\"üìà Overview Dashboard\")\n    \n    if df is not None and not df.empty:\n        col1, col2, col3, col4 = st.columns(4)\n        \n        with col1:\n            st.metric(\"üìÅ Total Rows\", f\"{len(df):,}\")\n        with col2:\n            st.metric(\"üìä Columns\", len(df.columns))\n        with col3:\n            missing_pct = (df.isnull().sum().sum() / (df.shape[0] * df.shape[1])) * 100\n            st.metric(\"‚ö†Ô∏è Missing\", f\"{missing_pct:.1f}%\")\n        with col4:\n            quality_score = calculate_data_quality_score(df)\n            st.metric(\"‚úÖ Quality Score\", f\"{quality_score}%\")\n        \n        st.markdown(\"---\")\n        \n        col1, col2 = st.columns(2)\n        \n        with col1:\n            st.subheader(\"üìä Column Types\")\n            type_counts = {\n                'Numeric': len(get_numeric_columns(df)),\n                'Categorical': len(get_categorical_columns(df)),\n                'Other': len(df.columns) - len(get_numeric_columns(df)) - len(get_categorical_columns(df))\n            }\n            \n            type_df = pd.DataFrame(list(type_counts.items()), columns=['Type', 'Count'])\n            fig = create_bar_chart(type_df, 'Type', 'Count')\n            if fig:\n                st.plotly_chart(fig, use_container_width=True)\n        \n        with col2:\n            st.subheader(\"üìà Data Preview\")\n            st.dataframe(df.head(10), use_container_width=True)\n            st.caption(f\"Showing 10 of {len(df):,} rows\")\n        \n        st.markdown(\"---\")\n        st.subheader(\"ü§ñ AI Quick Insights\")\n        \n        if st.button(\"‚ú® Generate Insights with AI\"):\n            with st.spinner(\"Analyzing your data...\"):\n                from modules.gemini_integration import generate_insights\n                insights = safe_execute(\"AI Insights\", generate_insights, df, \"general\")\n                if insights:\n                    st.success(insights)\n    else:\n        st.info(\"üì§ Please upload a dataset or load sample data from the sidebar to begin analysis.\")\n\nelif st.session_state.current_page == \"üîç Data Profiling\":\n    st.title(\"üîç Data Profiling\")\n    \n    if validate_dataframe(df):\n        profile = safe_execute(\"Data Profiling\", profile_data, df)\n        \n        if profile:\n            st.subheader(\"üìã Basic Information\")\n            col1, col2, col3, col4 = st.columns(4)\n            \n            with col1:\n                st.metric(\"Rows\", f\"{profile['basic_info']['rows']:,}\")\n            with col2:\n                st.metric(\"Columns\", profile['basic_info']['columns'])\n            with col3:\n                st.metric(\"Duplicates\", profile['basic_info']['duplicates'])\n            with col4:\n                st.metric(\"Quality\", f\"{profile['quality_score']}%\")\n            \n            st.markdown(\"---\")\n            \n            st.subheader(\"üìä Column Details\")\n            col_info_df = pd.DataFrame(profile['column_info']).T\n            st.dataframe(col_info_df, use_container_width=True)\n            \n            st.markdown(\"---\")\n            \n            col1, col2 = st.columns(2)\n            \n            with col1:\n                st.subheader(\"üìà Correlation Heatmap\")\n                fig = create_correlation_heatmap(df)\n                if fig:\n                    st.plotly_chart(fig, use_container_width=True)\n            \n            with col2:\n                st.subheader(\"üßπ Data Cleaning\")\n                \n                handle_missing = st.selectbox(\n                    \"Handle Missing Values\",\n                    [\"mean\", \"median\", \"mode\", \"drop\"],\n                    help=\"Strategy for missing values\"\n                )\n                \n                remove_dup = st.checkbox(\"Remove Duplicates\", value=True)\n                \n                handle_outliers = st.selectbox(\n                    \"Handle Outliers\",\n                    [\"none\", \"iqr\", \"zscore\"],\n                    help=\"Outlier detection method\"\n                )\n                \n                if st.button(\"üßπ Clean Data Now\"):\n                    with st.spinner(\"Cleaning data...\"):\n                        cleaned_df, report = safe_execute(\n                            \"Data Cleaning\",\n                            clean_data,\n                            df,\n                            handle_missing,\n                            remove_dup,\n                            handle_outliers\n                        )\n                        \n                        if cleaned_df is not None:\n                            st.session_state.cleaned_data = cleaned_df\n                            st.success(\"‚úÖ Data cleaned successfully!\")\n                            \n                            for action in report.get('actions', []):\n                                st.write(f\"‚Ä¢ {action}\")\n                            \n                            st.rerun()\n\nelif st.session_state.current_page == \"üìä EDA\":\n    st.title(\"üìä Exploratory Data Analysis\")\n    \n    if validate_dataframe(df):\n        tab1, tab2, tab3 = st.tabs([\"üìà Distributions\", \"üéØ Relationships\", \"üì¶ Comparisons\"])\n        \n        with tab1:\n            numeric_cols = get_numeric_columns(df)\n            \n            if numeric_cols:\n                selected_col = st.selectbox(\"Select Column\", numeric_cols)\n                \n                col1, col2 = st.columns(2)\n                \n                with col1:\n                    st.subheader(\"üìä Histogram\")\n                    fig = create_histogram(df, selected_col)\n                    if fig:\n                        st.plotly_chart(fig, use_container_width=True)\n                \n                with col2:\n                    st.subheader(\"üì¶ Box Plot\")\n                    fig = create_box_plot(df, selected_col)\n                    if fig:\n                        st.plotly_chart(fig, use_container_width=True)\n            else:\n                st.warning(\"No numeric columns available\")\n        \n        with tab2:\n            numeric_cols = get_numeric_columns(df)\n            \n            if len(numeric_cols) >= 2:\n                col1, col2 = st.columns(2)\n                \n                with col1:\n                    x_col = st.selectbox(\"X-axis\", numeric_cols, key=\"scatter_x\")\n                with col2:\n                    y_col = st.selectbox(\"Y-axis\", [c for c in numeric_cols if c != x_col], key=\"scatter_y\")\n                \n                categorical_cols = get_categorical_columns(df)\n                color_by = st.selectbox(\"Color by (optional)\", [None] + categorical_cols)\n                \n                fig = create_scatter_plot(df, x_col, y_col, color_by)\n                if fig:\n                    st.plotly_chart(fig, use_container_width=True)\n            else:\n                st.warning(\"Need at least 2 numeric columns\")\n        \n        with tab3:\n            categorical_cols = get_categorical_columns(df)\n            numeric_cols = get_numeric_columns(df)\n            \n            if categorical_cols and numeric_cols:\n                cat_col = st.selectbox(\"Categorical Column\", categorical_cols)\n                num_col = st.selectbox(\"Numeric Column\", numeric_cols)\n                \n                st.subheader(\"üéª Violin Plot\")\n                fig = create_violin_plot(df, num_col, cat_col)\n                if fig:\n                    st.plotly_chart(fig, use_container_width=True)\n            else:\n                st.warning(\"Need both categorical and numeric columns\")\n\nelif st.session_state.current_page == \"ü§ñ ML Models\":\n    st.title(\"ü§ñ Machine Learning Models\")\n    \n    if validate_dataframe(df, min_rows=50):\n        tab1, tab2, tab3 = st.tabs([\"üéØ Classification\", \"üìà Regression\", \"üîç Clustering\"])\n        \n        with tab1:\n            st.subheader(\"Classification Models\")\n            \n            all_cols = df.columns.tolist()\n            target_col = st.selectbox(\"Select Target Column\", all_cols)\n            \n            model_options = st.multiselect(\n                \"Select Models\",\n                [\"random_forest\", \"xgboost\", \"logistic\", \"lightgbm\"],\n                default=[\"random_forest\", \"xgboost\"]\n            )\n            \n            if st.button(\"üöÄ Train Classification Models\"):\n                with st.spinner(\"Training models...\"):\n                    results = safe_execute(\n                        \"Classification\",\n                        train_classification_models,\n                        df,\n                        target_col,\n                        model_options\n                    )\n                    \n                    if results:\n                        st.session_state.trained_models = results\n                        \n                        st.success(f\"‚úÖ Trained {len(results)} models!\")\n                        \n                        metrics_data = []\n                        for name, data in results.items():\n                            row = {'Model': name.upper()}\n                            row.update(data['metrics'])\n                            metrics_data.append(row)\n                        \n                        metrics_df = pd.DataFrame(metrics_data)\n                        st.dataframe(metrics_df.round(4), use_container_width=True)\n                        \n                        best_model = max(results.items(), key=lambda x: x[1]['metrics']['accuracy'])\n                        st.info(f\"‚≠ê Best Model: **{best_model[0].upper()}** with {best_model[1]['metrics']['accuracy']:.2%} accuracy\")\n                        \n                        if 'confusion_matrix' in best_model[1]:\n                            st.subheader(\"üìä Confusion Matrix (Best Model)\")\n                            cm_fig = create_confusion_matrix_plot(np.array(best_model[1]['confusion_matrix']))\n                            if cm_fig:\n                                st.plotly_chart(cm_fig, use_container_width=True)\n                        \n                        numeric_cols = get_numeric_columns(df.drop(columns=[target_col]))\n                        importance = get_feature_importance(best_model[1]['model'], numeric_cols)\n                        if importance:\n                            st.subheader(\"üéØ Feature Importance\")\n                            fig = create_feature_importance_plot(importance)\n                            if fig:\n                                st.plotly_chart(fig, use_container_width=True)\n        \n        with tab2:\n            st.subheader(\"Regression Models\")\n            \n            numeric_cols = get_numeric_columns(df)\n            if numeric_cols:\n                target_col = st.selectbox(\"Select Target Column\", numeric_cols, key=\"reg_target\")\n                \n                model_options = st.multiselect(\n                    \"Select Models\",\n                    [\"random_forest\", \"xgboost\", \"ridge\", \"lasso\"],\n                    default=[\"random_forest\", \"ridge\"],\n                    key=\"reg_models\"\n                )\n                \n                if st.button(\"üöÄ Train Regression Models\"):\n                    with st.spinner(\"Training models...\"):\n                        results = safe_execute(\n                            \"Regression\",\n                            train_regression_models,\n                            df,\n                            target_col,\n                            model_options\n                        )\n                        \n                        if results:\n                            metrics_data = []\n                            for name, data in results.items():\n                                row = {'Model': name.upper()}\n                                row.update(data['metrics'])\n                                metrics_data.append(row)\n                            \n                            metrics_df = pd.DataFrame(metrics_data)\n                            st.dataframe(metrics_df.round(4), use_container_width=True)\n                            \n                            best_model = min(results.items(), key=lambda x: x[1]['metrics']['rmse'])\n                            st.info(f\"‚≠ê Best Model: **{best_model[0].upper()}** with RMSE: {best_model[1]['metrics']['rmse']:.4f}\")\n            else:\n                st.warning(\"No numeric columns for regression\")\n        \n        with tab3:\n            st.subheader(\"Clustering Analysis\")\n            \n            n_clusters = st.slider(\"Number of Clusters\", 2, 10, 3)\n            method = st.selectbox(\"Clustering Method\", [\"kmeans\", \"dbscan\"])\n            \n            if st.button(\"üîç Perform Clustering\"):\n                with st.spinner(\"Clustering data...\"):\n                    result = safe_execute(\n                        \"Clustering\",\n                        perform_clustering,\n                        df,\n                        n_clusters,\n                        method\n                    )\n                    \n                    if result:\n                        st.success(f\"‚úÖ Found {result['n_clusters']} clusters\")\n                        \n                        df_with_clusters = df.copy()\n                        df_with_clusters['Cluster'] = result['labels']\n                        \n                        numeric_cols = get_numeric_columns(df)\n                        if len(numeric_cols) >= 2:\n                            fig = create_scatter_plot(\n                                df_with_clusters,\n                                numeric_cols[0],\n                                numeric_cols[1],\n                                'Cluster'\n                            )\n                            if fig:\n                                st.plotly_chart(fig, use_container_width=True)\n\nelif st.session_state.current_page == \"üìù Text Analytics\":\n    st.title(\"üìù Text Analytics\")\n    \n    if validate_dataframe(df):\n        text_cols = get_categorical_columns(df)\n        \n        if text_cols:\n            selected_col = st.selectbox(\"Select Text Column\", text_cols)\n            \n            if st.button(\"üîç Analyze Text\"):\n                with st.spinner(\"Analyzing text...\"):\n                    results = safe_execute(\n                        \"Text Analytics\",\n                        analyze_text_column,\n                        df,\n                        selected_col\n                    )\n                    \n                    if results:\n                        col1, col2 = st.columns(2)\n                        \n                        with col1:\n                            st.subheader(\"üìä Text Statistics\")\n                            stats = results.get('statistics', {})\n                            st.metric(\"Total Texts\", stats.get('total_texts', 0))\n                            st.metric(\"Avg Length\", f\"{stats.get('avg_length', 0):.0f} chars\")\n                            st.metric(\"Avg Words\", f\"{stats.get('avg_words', 0):.1f}\")\n                        \n                        with col2:\n                            st.subheader(\"üòä Sentiment Distribution\")\n                            if not results.get('sentiment', pd.DataFrame()).empty:\n                                sentiment_counts = results['sentiment']['label'].value_counts()\n                                fig = create_bar_chart(\n                                    pd.DataFrame({'Sentiment': sentiment_counts.index, 'Count': sentiment_counts.values}),\n                                    'Sentiment',\n                                    'Count'\n                                )\n                                if fig:\n                                    st.plotly_chart(fig, use_container_width=True)\n                        \n                        if results.get('wordcloud'):\n                            st.subheader(\"‚òÅÔ∏è Word Cloud\")\n                            import matplotlib.pyplot as plt\n                            fig, ax = plt.subplots(figsize=(10, 5))\n                            ax.imshow(results['wordcloud'], interpolation='bilinear')\n                            ax.axis('off')\n                            st.pyplot(fig)\n                        \n                        if results.get('bigrams'):\n                            st.subheader(\"üìù Top Bigrams\")\n                            bigrams_df = pd.DataFrame(results['bigrams'], columns=['Bigram', 'Frequency'])\n                            st.dataframe(bigrams_df, use_container_width=True)\n        else:\n            st.warning(\"No text columns found in dataset\")\n\nelif st.session_state.current_page == \"üöÄ Advanced ML\":\n    st.title(\"üöÄ Advanced ML Models\")\n    \n    if validate_dataframe(df):\n        from modules.advanced_ml import train_neural_network, train_xgboost, train_lightgbm, ensemble_models\n        from sklearn.model_selection import train_test_split\n        \n        tab1, tab2, tab3 = st.tabs([\"üß† Neural Networks\", \"‚ö° XGBoost/LightGBM\", \"ü§ù Ensemble\"])\n        \n        with tab1:\n            st.subheader(\"Multi-Layer Perceptron (Neural Network)\")\n            \n            task = st.radio(\"Task Type\", [\"classification\", \"regression\"])\n            \n            numeric_cols = get_numeric_columns(df)\n            categorical_cols = get_categorical_columns(df)\n            \n            if numeric_cols:\n                target_col = st.selectbox(\"Target Column\", df.columns.tolist())\n                \n                col1, col2 = st.columns(2)\n                with col1:\n                    hidden_layers = st.text_input(\"Hidden Layers (comma-separated)\", \"100,50\")\n                    activation = st.selectbox(\"Activation\", [\"relu\", \"tanh\", \"logistic\"])\n                \n                with col2:\n                    max_iter = st.number_input(\"Max Iterations\", 100, 2000, 500)\n                    test_size = st.slider(\"Test Size\", 0.1, 0.4, 0.2)\n                \n                if st.button(\"üöÄ Train Neural Network\"):\n                    with st.spinner(\"Training neural network...\"):\n                        try:\n                            layers = tuple(int(x.strip()) for x in hidden_layers.split(','))\n                            \n                            X = df.drop(columns=[target_col])\n                            y = df[target_col]\n                            \n                            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n                            \n                            result = train_neural_network(X_train, y_train, X_test, y_test, task, layers, activation, max_iter)\n                            \n                            if result:\n                                st.success(\"‚úÖ Model trained successfully!\")\n                                \n                                metrics = result['metrics']\n                                st.subheader(\"üìä Model Performance\")\n                                \n                                cols = st.columns(len(metrics))\n                                for i, (key, value) in enumerate(metrics.items()):\n                                    with cols[i]:\n                                        st.metric(key.replace('_', ' ').title(), f\"{value:.4f}\")\n                                \n                                st.session_state.trained_models['neural_network'] = result['model']\n                        except Exception as e:\n                            st.error(f\"‚ùå Error: {str(e)}\")\n        \n        with tab2:\n            st.subheader(\"Gradient Boosting Models\")\n            \n            model_type = st.selectbox(\"Model Type\", [\"XGBoost\", \"LightGBM\"])\n            task = st.radio(\"Task\", [\"classification\", \"regression\"], key=\"gb_task\")\n            \n            if numeric_cols:\n                target_col = st.selectbox(\"Target Column\", df.columns.tolist(), key=\"gb_target\")\n                \n                col1, col2 = st.columns(2)\n                with col1:\n                    max_depth = st.slider(\"Max Depth\", 3, 15, 6)\n                    n_estimators = st.slider(\"N Estimators\", 50, 500, 100)\n                \n                with col2:\n                    learning_rate = st.slider(\"Learning Rate\", 0.01, 0.3, 0.1)\n                    test_size = st.slider(\"Test Size\", 0.1, 0.4, 0.2, key=\"gb_test\")\n                \n                params = {\n                    'max_depth': max_depth,\n                    'n_estimators': n_estimators,\n                    'learning_rate': learning_rate,\n                    'random_state': 42\n                }\n                \n                if st.button(\"‚ö° Train Model\"):\n                    with st.spinner(f\"Training {model_type}...\"):\n                        try:\n                            X = df.drop(columns=[target_col])\n                            y = df[target_col]\n                            \n                            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n                            \n                            if model_type == \"XGBoost\":\n                                result = train_xgboost(X_train, y_train, X_test, y_test, task, params)\n                            else:\n                                params['verbosity'] = -1\n                                result = train_lightgbm(X_train, y_train, X_test, y_test, task, params)\n                            \n                            if result:\n                                st.success(\"‚úÖ Model trained successfully!\")\n                                \n                                metrics = result['metrics']\n                                st.subheader(\"üìä Model Performance\")\n                                \n                                cols = st.columns(len(metrics))\n                                for i, (key, value) in enumerate(metrics.items()):\n                                    with cols[i]:\n                                        st.metric(key.replace('_', ' ').title(), f\"{value:.4f}\")\n                                \n                                st.subheader(\"üéØ Feature Importance\")\n                                st.dataframe(result['feature_importance'].head(10), use_container_width=True)\n                                \n                                st.session_state.trained_models[model_type.lower()] = result['model']\n                        except Exception as e:\n                            st.error(f\"‚ùå Error: {str(e)}\")\n        \n        with tab3:\n            st.subheader(\"Ensemble Methods\")\n            st.info(\"Train multiple models first, then create an ensemble!\")\n            \n            if st.session_state.trained_models:\n                st.success(f\"‚úÖ {len(st.session_state.trained_models)} models available for ensembling\")\n                st.write(f\"Models: {', '.join(st.session_state.trained_models.keys())}\")\n            else:\n                st.warning(\"‚ö†Ô∏è No trained models yet. Train models in the tabs above first.\")\n\nelif st.session_state.current_page == \"‚è∞ Time Series\":\n    st.title(\"‚è∞ Time Series Analysis\")\n    \n    if validate_dataframe(df):\n        from modules.time_series import (\n            fit_arima_model, fit_sarima_model, decompose_time_series,\n            check_stationarity, auto_arima, plot_acf_pacf\n        )\n        \n        tab1, tab2, tab3, tab4 = st.tabs([\"üìä Decomposition\", \"üìà ARIMA\", \"üîÆ SARIMA\", \"üéØ Auto ARIMA\"])\n        \n        numeric_cols = get_numeric_columns(df)\n        \n        with tab1:\n            st.subheader(\"Seasonal Decomposition\")\n            \n            if numeric_cols:\n                ts_col = st.selectbox(\"Select Time Series Column\", numeric_cols)\n                period = st.number_input(\"Period (e.g., 12 for monthly)\", 2, 365, 12)\n                model_type = st.selectbox(\"Model Type\", [\"additive\", \"multiplicative\"])\n                \n                if st.button(\"üîç Decompose\"):\n                    with st.spinner(\"Decomposing time series...\"):\n                        result = decompose_time_series(df[ts_col], period, model_type)\n                        \n                        if result and 'error' not in result:\n                            st.success(\"‚úÖ Decomposition complete!\")\n                            \n                            fig, axes = plt.subplots(4, 1, figsize=(12, 10))\n                            \n                            result['observed'].plot(ax=axes[0], title='Observed')\n                            result['trend'].plot(ax=axes[1], title='Trend')\n                            result['seasonal'].plot(ax=axes[2], title='Seasonal')\n                            result['residual'].plot(ax=axes[3], title='Residual')\n                            \n                            plt.tight_layout()\n                            st.pyplot(fig)\n                        elif result and 'error' in result:\n                            st.error(result['error'])\n        \n        with tab2:\n            st.subheader(\"ARIMA Forecasting\")\n            \n            if numeric_cols:\n                ts_col = st.selectbox(\"Select Time Series Column\", numeric_cols, key=\"arima_col\")\n                \n                col1, col2, col3, col4 = st.columns(4)\n                with col1:\n                    p = st.number_input(\"p (AR order)\", 0, 5, 1)\n                with col2:\n                    d = st.number_input(\"d (Differencing)\", 0, 2, 1)\n                with col3:\n                    q = st.number_input(\"q (MA order)\", 0, 5, 1)\n                with col4:\n                    forecast_steps = st.number_input(\"Forecast Steps\", 1, 100, 10)\n                \n                if st.button(\"üìà Fit ARIMA\"):\n                    with st.spinner(\"Fitting ARIMA model...\"):\n                        result = fit_arima_model(df[ts_col], (p, d, q), forecast_steps)\n                        \n                        if result:\n                            st.success(f\"‚úÖ ARIMA({p},{d},{q}) fitted successfully!\")\n                            \n                            col1, col2 = st.columns(2)\n                            with col1:\n                                st.metric(\"AIC\", f\"{result['aic']:.2f}\")\n                            with col2:\n                                st.metric(\"BIC\", f\"{result['bic']:.2f}\")\n                            \n                            st.subheader(\"üîÆ Forecast\")\n                            forecast_df = pd.DataFrame({\n                                'Step': range(1, forecast_steps + 1),\n                                'Forecast': result['forecast']\n                            })\n                            st.dataframe(forecast_df, use_container_width=True)\n                            \n                            fig, ax = plt.subplots(figsize=(12, 6))\n                            ax.plot(df[ts_col].values[-50:], label='Historical', marker='o')\n                            ax.plot(range(len(df[ts_col])-1, len(df[ts_col])-1+forecast_steps), \n                                   result['forecast'], label='Forecast', marker='s', linestyle='--')\n                            ax.legend()\n                            ax.set_title('ARIMA Forecast')\n                            st.pyplot(fig)\n        \n        with tab3:\n            st.subheader(\"SARIMA (Seasonal ARIMA)\")\n            \n            if numeric_cols:\n                ts_col = st.selectbox(\"Select Time Series Column\", numeric_cols, key=\"sarima_col\")\n                \n                st.markdown(\"**Non-seasonal parameters**\")\n                col1, col2, col3 = st.columns(3)\n                with col1:\n                    p = st.number_input(\"p\", 0, 5, 1, key=\"sarima_p\")\n                with col2:\n                    d = st.number_input(\"d\", 0, 2, 1, key=\"sarima_d\")\n                with col3:\n                    q = st.number_input(\"q\", 0, 5, 1, key=\"sarima_q\")\n                \n                st.markdown(\"**Seasonal parameters**\")\n                col1, col2, col3, col4 = st.columns(4)\n                with col1:\n                    P = st.number_input(\"P\", 0, 3, 1)\n                with col2:\n                    D = st.number_input(\"D\", 0, 2, 1)\n                with col3:\n                    Q = st.number_input(\"Q\", 0, 3, 1)\n                with col4:\n                    s = st.number_input(\"s (period)\", 2, 365, 12)\n                \n                forecast_steps = st.number_input(\"Forecast Steps\", 1, 100, 10, key=\"sarima_steps\")\n                \n                if st.button(\"üìà Fit SARIMA\"):\n                    with st.spinner(\"Fitting SARIMA model...\"):\n                        result = fit_sarima_model(df[ts_col], (p, d, q), (P, D, Q, s), forecast_steps)\n                        \n                        if result:\n                            st.success(f\"‚úÖ SARIMA({p},{d},{q})x({P},{D},{Q},{s}) fitted!\")\n                            \n                            col1, col2 = st.columns(2)\n                            with col1:\n                                st.metric(\"AIC\", f\"{result['aic']:.2f}\")\n                            with col2:\n                                st.metric(\"BIC\", f\"{result['bic']:.2f}\")\n                            \n                            st.subheader(\"üîÆ Forecast\")\n                            forecast_df = pd.DataFrame({\n                                'Step': range(1, forecast_steps + 1),\n                                'Forecast': result['forecast']\n                            })\n                            st.dataframe(forecast_df, use_container_width=True)\n        \n        with tab4:\n            st.subheader(\"Auto ARIMA - Automatic Parameter Selection\")\n            \n            if numeric_cols:\n                ts_col = st.selectbox(\"Select Time Series Column\", numeric_cols, key=\"auto_col\")\n                \n                col1, col2, col3 = st.columns(3)\n                with col1:\n                    max_p = st.number_input(\"Max p\", 1, 5, 3)\n                with col2:\n                    max_d = st.number_input(\"Max d\", 1, 2, 2)\n                with col3:\n                    max_q = st.number_input(\"Max q\", 1, 5, 3)\n                \n                if st.button(\"üéØ Find Best ARIMA\"):\n                    with st.spinner(\"Searching for best parameters... This may take a while.\"):\n                        result = auto_arima(df[ts_col], max_p, max_d, max_q)\n                        \n                        if result:\n                            st.success(f\"‚úÖ Best model found: ARIMA{result['best_order']}\")\n                            \n                            col1, col2 = st.columns(2)\n                            with col1:\n                                st.metric(\"Best Order (p,d,q)\", str(result['best_order']))\n                                st.metric(\"AIC\", f\"{result['aic']:.2f}\")\n                            with col2:\n                                st.metric(\"BIC\", f\"{result['bic']:.2f}\")\n                            \n                            st.subheader(\"üîÆ 10-Step Forecast\")\n                            forecast_df = pd.DataFrame({\n                                'Step': range(1, 11),\n                                'Forecast': result['forecast']\n                            })\n                            st.dataframe(forecast_df, use_container_width=True)\n\nelif st.session_state.current_page == \"üì• Export Center\":\n    st.title(\"üì• Export Center\")\n    create_export_center(df, st.session_state.get('trained_models'))\n\nst.markdown(\"---\")\n\nst.subheader(\"üí¨ AI Chat Assistant\")\n\nshow_rate_limit_status()\n\nif 'chat_history' not in st.session_state:\n    st.session_state.chat_history = []\n\nchat_container = st.container()\nwith chat_container:\n    for message in st.session_state.chat_history[-10:]:\n        role = message.get(\"role\", \"user\")\n        content = message.get(\"content\", \"\")\n        \n        if role == \"user\":\n            st.markdown(f\"**You:** {content}\")\n        else:\n            st.markdown(f\"**AI:** {content}\")\n\ncan_request, wait_time = can_make_request()\n\nif not can_request and wait_time != \"hourly_limit\":\n    st.warning(f\"‚è≥ Please wait {wait_time} seconds before asking next question\")\nelif not can_request and wait_time == \"hourly_limit\":\n    st.error(f\"üö´ Hourly limit reached! ({get_remaining_requests()}/15 requests remaining)\")\n\nuser_input = st.text_input(\n    \"Ask AI about your data\",\n    placeholder=\"e.g., Show correlation between age and income\",\n    disabled=not can_request,\n    key=\"chat_input\"\n)\n\nif st.button(\"üì§ Send\", disabled=not can_request, type=\"primary\"):\n    if user_input:\n        st.session_state.chat_history.append({\"role\": \"user\", \"content\": user_input})\n        \n        with st.spinner(\"ü§ñ AI is thinking...\"):\n            context = get_data_context(df) if df is not None else {}\n            response = chat_with_gemini(\n                user_input,\n                st.session_state.chat_history,\n                context\n            )\n            \n            if response:\n                st.session_state.chat_history.append({\"role\": \"assistant\", \"content\": response})\n                update_rate_limit()\n                st.rerun()\n\nst.markdown(\"---\")\nst.caption(\"AI Data Analysis Platform by Muhammad Irbabul Salas | Powered by Gemini 2.5 Flash\")\n","size_bytes":38880},"modules/advanced_ml.py":{"content":"import pandas as pd\nimport numpy as np\nfrom typing import Dict, List, Optional, Tuple\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom sklearn.metrics import accuracy_score, f1_score, r2_score, mean_squared_error\nimport streamlit as st\nfrom utils.error_handler import log_error\n\ndef train_neural_network(\n    X_train: pd.DataFrame,\n    y_train: pd.Series,\n    X_test: pd.DataFrame,\n    y_test: pd.Series,\n    task: str = 'classification',\n    hidden_layers: Tuple[int] = (100, 50),\n    activation: str = 'relu',\n    max_iter: int = 500\n) -> Dict:\n    try:\n        if task == 'classification':\n            model = MLPClassifier(\n                hidden_layer_sizes=hidden_layers,\n                activation=activation,\n                max_iter=max_iter,\n                random_state=42,\n                early_stopping=True\n            )\n        else:\n            model = MLPRegressor(\n                hidden_layer_sizes=hidden_layers,\n                activation=activation,\n                max_iter=max_iter,\n                random_state=42,\n                early_stopping=True\n            )\n        \n        model.fit(X_train, y_train)\n        \n        train_pred = model.predict(X_train)\n        test_pred = model.predict(X_test)\n        \n        if task == 'classification':\n            train_score = accuracy_score(y_train, train_pred)\n            test_score = accuracy_score(y_test, test_pred)\n            f1 = f1_score(y_test, test_pred, average='weighted')\n            \n            metrics = {\n                'train_accuracy': train_score,\n                'test_accuracy': test_score,\n                'f1_score': f1\n            }\n        else:\n            train_score = r2_score(y_train, train_pred)\n            test_score = r2_score(y_test, test_pred)\n            rmse = np.sqrt(mean_squared_error(y_test, test_pred))\n            \n            metrics = {\n                'train_r2': train_score,\n                'test_r2': test_score,\n                'rmse': rmse\n            }\n        \n        return {\n            'model': model,\n            'metrics': metrics,\n            'predictions': test_pred,\n            'feature_names': X_train.columns.tolist()\n        }\n    except Exception as e:\n        log_error(\"Neural Network Training\", e)\n        return None\n\ndef train_xgboost(\n    X_train: pd.DataFrame,\n    y_train: pd.Series,\n    X_test: pd.DataFrame,\n    y_test: pd.Series,\n    task: str = 'classification',\n    params: Optional[Dict] = None\n) -> Dict:\n    try:\n        if params is None:\n            params = {\n                'max_depth': 6,\n                'learning_rate': 0.1,\n                'n_estimators': 100,\n                'random_state': 42\n            }\n        \n        if task == 'classification':\n            model = XGBClassifier(**params)\n        else:\n            model = XGBRegressor(**params)\n        \n        model.fit(X_train, y_train)\n        \n        train_pred = model.predict(X_train)\n        test_pred = model.predict(X_test)\n        \n        if task == 'classification':\n            train_score = accuracy_score(y_train, train_pred)\n            test_score = accuracy_score(y_test, test_pred)\n            f1 = f1_score(y_test, test_pred, average='weighted')\n            \n            metrics = {\n                'train_accuracy': train_score,\n                'test_accuracy': test_score,\n                'f1_score': f1\n            }\n        else:\n            train_score = r2_score(y_train, train_pred)\n            test_score = r2_score(y_test, test_pred)\n            rmse = np.sqrt(mean_squared_error(y_test, test_pred))\n            \n            metrics = {\n                'train_r2': train_score,\n                'test_r2': test_score,\n                'rmse': rmse\n            }\n        \n        feature_importance = pd.DataFrame({\n            'feature': X_train.columns,\n            'importance': model.feature_importances_\n        }).sort_values('importance', ascending=False)\n        \n        return {\n            'model': model,\n            'metrics': metrics,\n            'feature_importance': feature_importance,\n            'predictions': test_pred\n        }\n    except Exception as e:\n        log_error(\"XGBoost Training\", e)\n        return None\n\ndef train_lightgbm(\n    X_train: pd.DataFrame,\n    y_train: pd.Series,\n    X_test: pd.DataFrame,\n    y_test: pd.Series,\n    task: str = 'classification',\n    params: Optional[Dict] = None\n) -> Dict:\n    try:\n        if params is None:\n            params = {\n                'max_depth': 6,\n                'learning_rate': 0.1,\n                'n_estimators': 100,\n                'random_state': 42,\n                'verbosity': -1\n            }\n        \n        if task == 'classification':\n            model = LGBMClassifier(**params)\n        else:\n            model = LGBMRegressor(**params)\n        \n        model.fit(X_train, y_train)\n        \n        train_pred = model.predict(X_train)\n        test_pred = model.predict(X_test)\n        \n        if task == 'classification':\n            train_score = accuracy_score(y_train, train_pred)\n            test_score = accuracy_score(y_test, test_pred)\n            f1 = f1_score(y_test, test_pred, average='weighted')\n            \n            metrics = {\n                'train_accuracy': train_score,\n                'test_accuracy': test_score,\n                'f1_score': f1\n            }\n        else:\n            train_score = r2_score(y_train, train_pred)\n            test_score = r2_score(y_test, test_pred)\n            rmse = np.sqrt(mean_squared_error(y_test, test_pred))\n            \n            metrics = {\n                'train_r2': train_score,\n                'test_r2': test_score,\n                'rmse': rmse\n            }\n        \n        feature_importance = pd.DataFrame({\n            'feature': X_train.columns,\n            'importance': model.feature_importances_\n        }).sort_values('importance', ascending=False)\n        \n        return {\n            'model': model,\n            'metrics': metrics,\n            'feature_importance': feature_importance,\n            'predictions': test_pred\n        }\n    except Exception as e:\n        log_error(\"LightGBM Training\", e)\n        return None\n\ndef ensemble_models(\n    models: List[any],\n    X_test: pd.DataFrame,\n    y_test: pd.Series,\n    task: str = 'classification',\n    method: str = 'voting'\n) -> Dict:\n    try:\n        predictions = [model.predict(X_test) for model in models]\n        \n        if method == 'voting':\n            if task == 'classification':\n                ensemble_pred = np.round(np.mean(predictions, axis=0)).astype(int)\n                score = accuracy_score(y_test, ensemble_pred)\n                f1 = f1_score(y_test, ensemble_pred, average='weighted')\n                \n                metrics = {\n                    'accuracy': score,\n                    'f1_score': f1\n                }\n            else:\n                ensemble_pred = np.mean(predictions, axis=0)\n                score = r2_score(y_test, ensemble_pred)\n                rmse = np.sqrt(mean_squared_error(y_test, ensemble_pred))\n                \n                metrics = {\n                    'r2_score': score,\n                    'rmse': rmse\n                }\n        \n        return {\n            'predictions': ensemble_pred,\n            'metrics': metrics,\n            'individual_predictions': predictions\n        }\n    except Exception as e:\n        log_error(\"Ensemble Models\", e)\n        return None\n","size_bytes":7749},"attached_assets/TROUBLESHOOTING_1763157388117.md":{"content":"# üîß Troubleshooting Guide\n\n**AI Data Analysis Platform - Common Issues & Solutions**\n\n---\n\n## üö® Installation Issues\n\n### Issue: Package Installation Fails\n\n**Error**: `ERROR: Could not find a version that satisfies the requirement...`\n\n**Solution**:\n```bash\n# Update pip first\npip install --upgrade pip\n\n# Install packages one by one to identify issue\npip install streamlit\npip install google-generativeai\n# etc.\n\n# Or use specific versions\npip install streamlit==1.31.0\n```\n\n---\n\n### Issue: Python Version Mismatch\n\n**Error**: `Python 3.11+ required`\n\n**Solution**:\n```bash\n# Check Python version\npython --version\n\n# If < 3.11, upgrade Python\n# Download from: https://www.python.org/downloads/\n\n# Or use pyenv\npyenv install 3.11.7\npyenv global 3.11.7\n```\n\n---\n\n## üîë API Key Issues\n\n### Issue: GEMINI_API_KEY Not Found\n\n**Error**: `GEMINI_API_KEY not found in environment`\n\n**Solutions**:\n\n**On Replit:**\n1. Click Secrets (üîí icon in sidebar)\n2. Add new secret: `GEMINI_API_KEY`\n3. Paste your API key\n4. Restart app\n\n**Locally:**\n```bash\n# Add to .bashrc or .zshrc\nexport GEMINI_API_KEY=\"your_key_here\"\n\n# Or use .env file\necho \"GEMINI_API_KEY=your_key_here\" > .env\n\n# Restart terminal\n```\n\n---\n\n### Issue: API Key Invalid\n\n**Error**: `401 Unauthorized` or `Invalid API key`\n\n**Solution**:\n1. Get **NEW** API key from https://aistudio.google.com/app/apikey\n2. Ensure you copy the ENTIRE key (no spaces)\n3. Update in Replit Secrets\n4. Restart application\n\n---\n\n### Issue: API Rate Limit\n\n**Error**: `429 Too Many Requests` or `Quota exceeded`\n\n**Expected Behavior**: The app shows countdown timer\n\n**Solutions**:\n- **Wait** for cooldown period (1 minute)\n- **Free Tier Limits**: 15 requests/hour\n- Use **manual features** during cooldown\n- **Upgrade** to paid tier if needed\n\n---\n\n## üìÇ Data Upload Issues\n\n### Issue: Upload Failed - File Too Large\n\n**Error**: `File size exceeds limit`\n\n**Solution**:\n- **Max size**: 200MB\n- **Compress** data or **sample** it\n- Try **Parquet** format (more efficient)\n\n```python\n# Sample large dataset\ndf_sample = df.sample(frac=0.1)  # 10% sample\ndf_sample.to_csv('sampled_data.csv', index=False)\n```\n\n---\n\n### Issue: Upload Failed - Format Error\n\n**Error**: `ParserError` or `Cannot read file`\n\n**Solutions**:\n1. **Check file format**:\n   - CSV: Must be comma-separated\n   - Excel: Must be .xlsx or .xls\n   - JSON: Must be valid JSON\n\n2. **Fix encoding**:\n   ```bash\n   # Convert to UTF-8\n   iconv -f ISO-8859-1 -t UTF-8 input.csv > output.csv\n   ```\n\n3. **Re-export from Excel**:\n   - Open in Excel\n   - Save As ‚Üí CSV (UTF-8)\n\n---\n\n### Issue: Missing Columns After Upload\n\n**Error**: Some columns not showing\n\n**Solutions**:\n- Check if file has **headers**\n- Verify **delimiter** (comma vs tab)\n- Ensure **no special characters** in column names\n\n---\n\n## ü§ñ Machine Learning Issues\n\n### Issue: Model Training Failed\n\n**Error**: `ValueError` or `Not enough data`\n\n**Solutions**:\n- **Minimum rows**: 50 for classification/regression\n- **Check target column**: Must exist and have valid values\n- **Numeric features**: ML needs numeric columns\n- **Clean data first**: Remove missing values\n\n---\n\n### Issue: All Models Failed\n\n**Error**: Every model returns error\n\n**Solutions**:\n1. **Data Quality Check**:\n   - Run data profiling first\n   - Clean data (handle missing values)\n   - Ensure target column is correct type\n\n2. **Feature Check**:\n   - Classification: Need categorical or binary target\n   - Regression: Need numeric target\n   - At least 2-3 numeric features\n\n3. **Data Size**:\n   - Too small: Add more data\n   - Too large: Sample it\n\n---\n\n### Issue: Low Model Accuracy\n\n**Not an error, but common question**\n\n**Solutions**:\n- **Clean data better**: Remove outliers, handle missing values\n- **Feature engineering**: Create new features\n- **Try different models**: XGBoost often performs better\n- **Tune hyperparameters**: Enable tuning option\n- **More data**: Collect more training samples\n\n---\n\n## üìä Visualization Issues\n\n### Issue: Charts Not Rendering\n\n**Error**: Blank space where chart should be\n\n**Solutions**:\n1. **Check data**:\n   - Need numeric columns for most charts\n   - Need at least 2 values\n\n2. **Browser**:\n   - Refresh page\n   - Clear cache\n   - Try different browser (Chrome recommended)\n\n3. **Plotly**:\n   ```bash\n   # Reinstall plotly\n   pip uninstall plotly\n   pip install plotly==5.18.0\n   ```\n\n---\n\n### Issue: Correlation Heatmap Empty\n\n**Error**: \"Need at least 2 numeric columns\"\n\n**Solution**:\n- Dataset must have **2+ numeric columns**\n- Convert categorical to numeric if needed\n- Check data types in Data Profiling dashboard\n\n---\n\n## üìù Text Analytics Issues\n\n### Issue: Sentiment Analysis Failed\n\n**Error**: `TextBlob error` or `NLTK data not found`\n\n**Solution**:\n```python\n# Download NLTK data\nimport nltk\nnltk.download('punkt')\nnltk.download('vader_lexicon')\nnltk.download('stopwords')\n```\n\nOr run in terminal:\n```bash\npython -c \"import nltk; nltk.download('all')\"\n```\n\n---\n\n### Issue: Word Cloud Empty\n\n**Error**: Blank word cloud or \"No text data\"\n\n**Solutions**:\n- **Check column has text**: Not empty\n- **Remove stopwords**: Common words filter out\n- **Verify encoding**: UTF-8 recommended\n\n---\n\n## üíæ Export Issues\n\n### Issue: Download Failed\n\n**Error**: Download button not working\n\n**Solutions**:\n1. **Browser settings**:\n   - Allow downloads from this site\n   - Check download folder permissions\n\n2. **File size**:\n   - Large files may timeout\n   - Try smaller datasets\n\n3. **Format**:\n   - Try different export format\n   - CSV usually most reliable\n\n---\n\n### Issue: PDF Report Blank\n\n**Error**: PDF downloads but is empty\n\n**Solution**:\n- Run analysis first (PDF needs content)\n- Check browser PDF viewer\n- Try opening in Adobe Reader\n\n---\n\n## üåê Deployment Issues (Railway)\n\n### Issue: Build Failed on Railway\n\n**Error**: Build logs show error\n\n**Solutions**:\n1. **Check requirements**:\n   - All dependencies in requirements.txt\n   - Correct versions specified\n\n2. **Procfile**:\n   ```\n   web: streamlit run app.py --server.port=$PORT --server.address=0.0.0.0 --server.headless=true\n   ```\n\n3. **Runtime**:\n   - Ensure Python 3.11+ available\n   - Check Railway build logs\n\n---\n\n### Issue: App Crashes After Deploy\n\n**Error**: 503 or 502 error\n\n**Solutions**:\n1. **Check logs** in Railway dashboard\n2. **Verify environment variables**:\n   - `GEMINI_API_KEY` is set\n   - No typos in variable names\n\n3. **Port binding**:\n   - Must use `$PORT` from Railway\n   - Not hardcoded port\n\n---\n\n### Issue: App Very Slow\n\n**Error**: Long loading times\n\n**Solutions**:\n1. **Upgrade Railway plan**: Free tier has limits\n2. **Optimize code**: Add caching\n3. **Reduce data size**: Sample large datasets\n4. **Check region**: Use region closest to users\n\n---\n\n## üí¨ AI Chat Issues\n\n### Issue: Chat Not Responding\n\n**Error**: No response from AI\n\n**Solutions**:\n1. **Check API key**: Valid and set correctly\n2. **Rate limiting**: Wait for cooldown\n3. **Internet**: Verify connection\n4. **Logs**: Check for specific errors\n\n---\n\n### Issue: Chat Gives Wrong Answers\n\n**Not an error, AI limitation**\n\n**Solutions**:\n- **Be specific**: Clear, detailed questions\n- **Provide context**: \"Using column X, analyze Y\"\n- **Try rephrasing**: Different wording might help\n- **Use manual features**: For precise control\n\n---\n\n## üñ•Ô∏è Performance Issues\n\n### Issue: App Runs Slow\n\n**Solutions**:\n1. **Restart app**: Fresh start\n2. **Clear session**: Reload page\n3. **Reduce data**: Work with sample\n4. **Close other tabs**: Free up RAM\n\n---\n\n### Issue: Out of Memory\n\n**Error**: `MemoryError`\n\n**Solutions**:\n1. **Sample data**:\n   ```python\n   df_sample = df.sample(n=10000)  # Use 10K rows\n   ```\n\n2. **Reduce columns**: Remove unnecessary\n3. **Use Parquet**: More memory efficient\n4. **Batch processing**: Analyze in chunks\n\n---\n\n## üîç Debugging Tips\n\n### Enable Debug Mode\n\n```python\n# In app.py, add at top:\nimport streamlit as st\nst.write(\"Debug info:\", st.session_state)\n```\n\n### Check Logs\n\n**On Replit:**\n- View console for error messages\n\n**On Railway:**\n- Dashboard ‚Üí Deployments ‚Üí View Logs\n\n### Common Error Patterns\n\n| Error | Likely Cause | Fix |\n|-------|-------------|-----|\n| KeyError | Column not found | Check column names |\n| ValueError | Wrong data type | Convert/clean data |\n| MemoryError | Dataset too large | Sample data |\n| 429 Error | Rate limit | Wait for cooldown |\n| 401 Error | Invalid API key | Update key |\n\n---\n\n## üìû Getting Help\n\nIf you're still stuck:\n\n1. **Check error message**: Often tells you what's wrong\n2. **Search error**: Google the specific error\n3. **Review documentation**: README.md, this guide\n4. **Simplify**: Try with sample dataset first\n5. **Restart**: Sometimes fixes mysterious issues\n\n---\n\n## ‚úÖ Prevention Tips\n\n**Best Practices:**\n- ‚úÖ Start with sample datasets to learn\n- ‚úÖ Clean data before ML\n- ‚úÖ Save work frequently (download results)\n- ‚úÖ Monitor API usage\n- ‚úÖ Keep Gemini API key secure\n- ‚úÖ Test on small data first\n- ‚úÖ Read error messages carefully\n\n---\n\n**Still Having Issues?**\n\nMost problems are solved by:\n1. Restarting the application\n2. Checking the API key\n3. Verifying data quality\n4. Reading error messages\n\n---\n\n**Muhammad Irbabul Salas**\n*AI Data Analysis Platform*\n","size_bytes":9249},"utils/rate_limiter.py":{"content":"import streamlit as st\nimport time\nfrom datetime import datetime, timedelta\nfrom typing import Tuple, Union\n\nRATE_LIMIT_SECONDS = 60\nMAX_REQUESTS_PER_HOUR = 15\n\ndef initialize_rate_limiter():\n    if 'last_request_time' not in st.session_state:\n        st.session_state.last_request_time = None\n    if 'request_timestamps' not in st.session_state:\n        st.session_state.request_timestamps = []\n    if 'question_queue' not in st.session_state:\n        st.session_state.question_queue = []\n\ndef can_make_request() -> Tuple[bool, Union[int, str]]:\n    current_time = datetime.now()\n    \n    st.session_state.request_timestamps = [\n        ts for ts in st.session_state.request_timestamps \n        if current_time - ts < timedelta(hours=1)\n    ]\n    \n    if len(st.session_state.request_timestamps) >= MAX_REQUESTS_PER_HOUR:\n        return False, \"hourly_limit\"\n    \n    if st.session_state.last_request_time:\n        time_since_last = (current_time - st.session_state.last_request_time).total_seconds()\n        if time_since_last < RATE_LIMIT_SECONDS:\n            return False, int(RATE_LIMIT_SECONDS - time_since_last)\n    \n    return True, 0\n\ndef get_remaining_time() -> int:\n    if not st.session_state.last_request_time:\n        return 0\n    \n    current_time = datetime.now()\n    time_since_last = (current_time - st.session_state.last_request_time).total_seconds()\n    remaining = max(0, RATE_LIMIT_SECONDS - time_since_last)\n    return int(remaining)\n\ndef update_rate_limit():\n    current_time = datetime.now()\n    st.session_state.last_request_time = current_time\n    st.session_state.request_timestamps.append(current_time)\n\ndef get_remaining_requests() -> int:\n    return MAX_REQUESTS_PER_HOUR - len(st.session_state.request_timestamps)\n\ndef show_rate_limit_status():\n    remaining_requests = get_remaining_requests()\n    \n    col1, col2 = st.columns([3, 1])\n    with col1:\n        st.caption(f\"üìä Remaining requests this hour: **{remaining_requests}/{MAX_REQUESTS_PER_HOUR}**\")\n    \n    with col2:\n        if st.button(\"‚ÑπÔ∏è\", key=\"api_limits_info\"):\n            st.info(\"\"\"\n            **Free API Limits:**\n            - 1 minute between questions\n            - 15 requests per hour\n            - Resets every hour\n            \"\"\")\n\ndef show_cooldown_timer():\n    can_request, wait_time = can_make_request()\n    \n    if not can_request and wait_time != \"hourly_limit\":\n        st.warning(f\"‚è≥ **Please wait {wait_time} seconds before asking next question**\")\n        \n        progress_placeholder = st.empty()\n        status_placeholder = st.empty()\n        \n        for remaining in range(wait_time, 0, -1):\n            progress = 1 - (remaining / RATE_LIMIT_SECONDS)\n            progress_placeholder.progress(progress)\n            status_placeholder.text(f\"‚è±Ô∏è {remaining}s remaining...\")\n            time.sleep(1)\n            \n            if get_remaining_time() == 0:\n                break\n        \n        progress_placeholder.progress(1.0)\n        status_placeholder.success(\"‚úÖ Ready! You can ask now.\")\n        time.sleep(1)\n        st.rerun()\n        \n    elif not can_request and wait_time == \"hourly_limit\":\n        st.error(f\"\"\"\n        üö´ **Hourly limit reached!**\n        \n        You've used all {MAX_REQUESTS_PER_HOUR} requests this hour.\n        \n        **Meanwhile, you can:**\n        ‚Ä¢ Explore dashboards\n        ‚Ä¢ Download results\n        ‚Ä¢ Try sample datasets\n        ‚Ä¢ Use manual features\n        \n        üí° Limit resets in approximately {get_reset_time()} minutes\n        \"\"\")\n        return False\n    \n    return True\n\ndef get_reset_time() -> int:\n    if not st.session_state.request_timestamps:\n        return 0\n    oldest_request = min(st.session_state.request_timestamps)\n    reset_time = oldest_request + timedelta(hours=1)\n    minutes_until_reset = int((reset_time - datetime.now()).total_seconds() / 60)\n    return max(0, minutes_until_reset)\n","size_bytes":3907},"replit.md":{"content":"# AI Data Analysis Platform\n\n## Overview\nA comprehensive AI-powered data analysis platform built with Streamlit that provides automated machine learning, interactive visualizations, text analytics, and intelligent data processing with Google Gemini 2.5 Flash AI. The platform offers:\n- **AI Chat Assistant** - Conversational interface powered by Gemini 2.5 Flash with function calling\n- **Automated Machine Learning** - 10+ algorithms with automatic comparison and tuning\n- **Interactive Dashboards** - Multi-page responsive interface with comprehensive analytics\n- **Text Analytics** - Sentiment analysis, topic modeling, and word clouds\n- **Comprehensive Export** - PDF reports, Excel files, trained models, and Jupyter notebooks\n- **Multi-format Support** - CSV, Excel, JSON, Parquet, TSV file handling\n- **Advanced Cleaning** - Automated data profiling and quality assessment\n\n## Tech Stack\n- **Frontend**: Streamlit (responsive web framework)\n- **AI**: Google Gemini 2.5 Flash (with function calling)\n- **ML Libraries**: scikit-learn, XGBoost, LightGBM\n- **Visualization**: Plotly (interactive charts)\n- **Data Processing**: Pandas, NumPy\n- **Text Analytics**: TextBlob, WordCloud\n- **Export**: FPDF, openpyxl, joblib\n- **Python**: 3.11+\n\n## Setup\n1. **API Key**: Aplikasi memerlukan `GEMINI_API_KEY` untuk berfungsi\n   - Dapatkan dari [Google AI Studio](https://makersuite.google.com/app/apikey)\n   - Tambahkan ke Secrets dengan nama `GEMINI_API_KEY`\n   \n2. **Dependencies**: Terinstall otomatis via uv\n   - streamlit\n   - google-generativeai\n   - pandas\n\n## Project Structure\n```\nai-data-analysis/\n‚îú‚îÄ‚îÄ app.py                          # Main Streamlit application\n‚îú‚îÄ‚îÄ requirements.txt                # Python dependencies\n‚îú‚îÄ‚îÄ pyproject.toml                  # UV package manager config\n‚îú‚îÄ‚îÄ Procfile                        # Railway deployment config\n‚îú‚îÄ‚îÄ railway.json                    # Railway build settings\n‚îÇ\n‚îú‚îÄ‚îÄ modules/                        # Core modules\n‚îÇ   ‚îú‚îÄ‚îÄ data_processing.py          # Data loading & cleaning\n‚îÇ   ‚îú‚îÄ‚îÄ ml_models.py                # ML training & evaluation\n‚îÇ   ‚îú‚îÄ‚îÄ visualizations.py           # Chart generation\n‚îÇ   ‚îú‚îÄ‚îÄ text_analytics.py           # NLP functions\n‚îÇ   ‚îú‚îÄ‚îÄ gemini_integration.py       # AI function calling\n‚îÇ   ‚îî‚îÄ‚îÄ export_handler.py           # Export functionality\n‚îÇ\n‚îú‚îÄ‚îÄ utils/                          # Utilities\n‚îÇ   ‚îú‚îÄ‚îÄ error_handler.py            # Error management\n‚îÇ   ‚îú‚îÄ‚îÄ rate_limiter.py             # API rate limiting\n‚îÇ   ‚îî‚îÄ‚îÄ helpers.py                  # Helper functions\n‚îÇ\n‚îú‚îÄ‚îÄ assets/                         # Static files\n‚îÇ   ‚îú‚îÄ‚îÄ profile_photo.jpg           # Author photo\n‚îÇ   ‚îî‚îÄ‚îÄ sample_datasets/            # Sample data\n‚îÇ\n‚îú‚îÄ‚îÄ .streamlit/\n‚îÇ   ‚îî‚îÄ‚îÄ config.toml                 # Streamlit configuration\n‚îÇ\n‚îî‚îÄ‚îÄ docs/                           # Documentation\n    ‚îú‚îÄ‚îÄ DEPLOYMENT.md               # Railway deployment guide\n    ‚îî‚îÄ‚îÄ TROUBLESHOOTING.md          # Common issues\n```\n\n## Features\n### Current Features (Updated: November 14, 2025)\n- ‚úÖ **Overview Dashboard** - Data quality metrics, quick insights dengan Gemini AI\n- ‚úÖ **Data Profiling** - Comprehensive data analysis, correlation heatmaps, automated cleaning\n- ‚úÖ **EDA (Exploratory Data Analysis)** - Distributions, relationships, comparisons dengan visualizations\n- ‚úÖ **ML Models** - Classification, Regression, Clustering dengan Random Forest, Logistic Regression, SVM\n- ‚úÖ **Advanced ML** - XGBoost, LightGBM, Neural Networks (MLP), Ensemble methods\n- ‚úÖ **Time Series Analysis** - ARIMA, SARIMA, seasonal decomposition, Auto ARIMA, stationarity tests\n- ‚úÖ **Text Analytics** - Sentiment analysis, WordCloud, bigrams, NLP features\n- ‚úÖ **Export Center** - Export cleaned data, trained models, comprehensive reports\n- ‚úÖ **Gemini AI Integration** - Chat assistant untuk data insights and analysis guidance\n- ‚úÖ **Rate Limiting** - Smart API rate management\n- ‚úÖ **Responsive UI** - Mobile-friendly interface\n\n### Newly Added Advanced Features\n- üéØ **XGBoost & LightGBM** - State-of-the-art gradient boosting models\n- üß† **Neural Networks** - Multi-layer perceptron untuk classification/regression\n- üìà **Time Series Forecasting** - ARIMA, SARIMA dengan automatic parameter selection\n- üìä **Seasonal Decomposition** - Trend, seasonal, residual analysis\n- ü§ù **Ensemble Methods** - Model combination untuk better performance\n- üé® **Feature Importance** - Understanding model decisions\n\n### Future Enhancements\nFitur yang masih dalam rencana:\n- Deep Learning (TensorFlow/Keras for CNN, LSTM)\n- Prophet time series forecasting\n- PostgreSQL database integration untuk project persistence\n- Bayesian Optimization (Optuna) untuk hyperparameter tuning\n- REST API endpoints untuk model deployment\n- Cloud storage integration (Google Drive, AWS S3)\n- Real-time collaboration features\n- Enhanced security dan authentication\n\n## Configuration\n- **Port**: 5000 (required untuk Replit)\n- **Host**: 0.0.0.0 (required untuk proxy)\n- **CORS**: Disabled untuk kompatibilitas Replit\n- **XSRF Protection**: Disabled untuk development\n\n## Running Locally\n```bash\nstreamlit run app.py --server.port=5000 --server.address=0.0.0.0\n```\n\n## Deployment\nConfigured untuk Replit Autoscale deployment. Klik tombol \"Deploy\" untuk publish.\n\n## System Architecture\n\n### Core Processing Modules\n1. **Data Processing Layer** - Multi-format parsing, automated profiling, cleaning strategies\n2. **Machine Learning Engine** - 10+ algorithms, hyperparameter tuning, clustering, PCA\n3. **Text Analytics Module** - Sentiment analysis, word clouds, topic extraction\n4. **Visualization Engine** - Interactive Plotly charts, specialized ML visualizations\n5. **AI Chat Integration** - Gemini 2.5 Flash with function calling capabilities\n6. **Export Handler** - Multi-format export (CSV, Excel, JSON, PDF, models)\n\n### Design Patterns\n- **Separation of Concerns** - Each module has single responsibility\n- **Defensive Programming** - Extensive validation with graceful degradation\n- **Progressive Enhancement** - Core functionality works without advanced features\n- **Mobile-First Responsive** - CSS media queries for different screen sizes\n\n## External Dependencies\n\n### AI & ML Services\n- **Google Gemini 2.5 Flash API** - Rate limits: 15 requests/minute, 1500/day (free tier)\n- Authentication via `GEMINI_API_KEY` environment variable\n\n### Key Python Libraries\n- **Core**: streamlit, pandas, numpy\n- **ML**: scikit-learn, xgboost, lightgbm, joblib\n- **Visualization**: plotly, matplotlib, wordcloud\n- **Text**: textblob\n- **Export**: fpdf, openpyxl\n\n## Recent Changes\n- 2025-11-14: Successfully migrated project to Replit environment\n- 2025-11-14: Installed all required dependencies (16 packages)\n- 2025-11-14: Configured workflow for Streamlit on port 5000\n- 2025-11-14: Verified app is running with all features functional\n- 2025-11-14: Updated documentation with comprehensive architecture details\n\n## User Preferences\n- **Communication**: Simple, everyday language\n- **Framework**: Streamlit for rapid data science development\n- **Author**: Muhammad Irbabul Salas\n\n## Future Enhancements\nPlanned features from task list:\n- Deep Learning (TensorFlow/Keras for CNN, LSTM)\n- Prophet time series forecasting\n- PostgreSQL database integration for project persistence\n- Bayesian Optimization (Optuna) for hyperparameter tuning\n- REST API endpoints for model deployment\n- Cloud storage integration (Google Drive, AWS S3)\n- Real-time collaboration features\n- Enhanced security and authentication\n- Performance optimization for big data (caching, lazy loading, parallel processing)\n","size_bytes":7766}},"version":2}